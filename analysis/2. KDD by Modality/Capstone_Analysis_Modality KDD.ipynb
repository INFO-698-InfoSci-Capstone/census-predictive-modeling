{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data Sources, Make DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set base path for reproducibility\n",
    "# Save initial data to a folder \"Capstone Project Data_Cleaned\" in the current working directory\n",
    "base_path = os.path.join(os.getcwd(), \"Capstone Project Data_Cleaned\")\n",
    "\n",
    "# Create DFs - Undergrad Only Data\n",
    "df_all_inperson = pd.read_excel(os.path.join(base_path, \"df_all_inperson.xlsx\"))\n",
    "df_all_online = pd.read_excel(os.path.join(base_path, \"df_all_online.xlsx\"))\n",
    "df_all = pd.read_excel(os.path.join(base_path, \"df_all.xlsx\"))\n",
    "\n",
    "df_fall_all_inperson = pd.read_excel(os.path.join(base_path, \"df_fall_all_inperson.xlsx\"))\n",
    "df_fall_all_online = pd.read_excel(os.path.join(base_path, \"df_fall_all_online.xlsx\"))\n",
    "df_fall_all = pd.read_excel(os.path.join(base_path, \"df_fall_all.xlsx\"))\n",
    "\n",
    "df_spring_all_inperson = pd.read_excel(os.path.join(base_path, \"df_spring_all_inperson.xlsx\"))\n",
    "df_spring_all_online = pd.read_excel(os.path.join(base_path, \"df_spring_all_online.xlsx\"))\n",
    "df_spring_all = pd.read_excel(os.path.join(base_path, \"df_spring_all.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionaries \n",
    "\n",
    "# All Dictionary\n",
    "dfs_all = {\n",
    "    \"df_all\": df_all,\n",
    "    \"df_fall_all\": df_fall_all,\n",
    "    \"df_spring_all\": df_spring_all\n",
    "}\n",
    "\n",
    "# In-Person Dictionary\n",
    "dfs_inperson = {\n",
    "    \"df_all_inperson\": df_all_inperson,\n",
    "    \"df_fall_all_inperson\": df_fall_all_inperson,\n",
    "    \"df_spring_all_inperson\": df_spring_all_inperson\n",
    "}\n",
    "\n",
    "# Online Dictionary\n",
    "dfs_online = {\n",
    "    \"df_all_online\": df_all_online,\n",
    "    \"df_fall_all_online\": df_fall_all_online,\n",
    "    \"df_spring_all_online\": df_spring_all_online\n",
    "}\n",
    "\n",
    "dfs_everything = {**dfs_all, **dfs_inperson, **dfs_online}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore DF size by Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF sizes in dfs_all:\n",
      "   df_all: 1559 rows, 27 columns\n",
      "   df_fall_all: 766 rows, 27 columns\n",
      "   df_spring_all: 793 rows, 27 columns\n",
      "\n",
      "DF sizes in dfs_inperson:\n",
      "   df_all_inperson: 339 rows, 27 columns\n",
      "   df_fall_all_inperson: 165 rows, 27 columns\n",
      "   df_spring_all_inperson: 174 rows, 27 columns\n",
      "\n",
      "DF sizes in dfs_online:\n",
      "   df_all_online: 1220 rows, 27 columns\n",
      "   df_fall_all_online: 601 rows, 27 columns\n",
      "   df_spring_all_online: 619 rows, 27 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"DF sizes in dfs_all:\")\n",
    "for name, df in dfs_all.items():\n",
    "    print(f\"   {name}: {df.shape[0]} rows, {df.shape[1]} columns\") #df.shape[] for #rows, #cols\n",
    "\n",
    "print(\"\\nDF sizes in dfs_inperson:\")\n",
    "for name, df in dfs_inperson.items():\n",
    "    print(f\"   {name}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "print(\"\\nDF sizes in dfs_online:\")\n",
    "for name, df in dfs_online.items():\n",
    "    print(f\"   {name}: {df.shape[0]} rows, {df.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Modality: In-Person vs Online </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-Person vs Online Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online Classes Count:\n",
      "   df_all_online: has 1220 online classes\n",
      "   df_fall_all_online: has 601 online classes\n",
      "   df_spring_all_online: has 619 online classes\n",
      "\n",
      "In-Person Classes Count:\n",
      "   df_all_inperson: has 339 in-person classes\n",
      "   df_fall_all_inperson: has 165 in-person classes\n",
      "   df_spring_all_inperson: has 174 in-person classes\n"
     ]
    }
   ],
   "source": [
    "print(\"Online Classes Count:\")\n",
    "for name, df in dfs_online.items():\n",
    "    print(f\"   {name}: has {df.shape[0]} online classes\")\n",
    "\n",
    "print(\"\\nIn-Person Classes Count:\")\n",
    "for name, df in dfs_inperson.items():\n",
    "    print(f\"   {name}: has {df.shape[0]} in-person classes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online/In-Person Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_all_inperson_online = {\n",
    "    \"df_all_inperson\": df_all_inperson,\n",
    "    \"df_all_online\": df_all_online\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Function for sorting results in academic year order: semester_order_func </h3>\n",
    "Fall 2021, Spring 2022, Fall 2022, Spring 2023, Fall 2023, Spring 2024, Fall 2024, Spring 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy: label Fall/Spring starting with the same year, to count them as the same academic year\n",
    "# e.g. Fall 2021 & Spring 2022 will turn into 2021.0 and 2021.5, to group as the 2021 academic year\n",
    "\n",
    "def semester_order_func(sem):\n",
    "    season, year = sem.split()\n",
    "    year = int(year)\n",
    "    if season == \"Fall\":\n",
    "        return year + 0.0           # Fall 2021 turns into 2021.0; Fall 2021 into 2022.0; etc\n",
    "    elif season == \"Spring\":\n",
    "        return (year - 1) + 0.5     # Spring 2022 - 1 + 0.5 = 2021.5 so that it'll follow Fall 2021.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online/In-Person by Semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_all_inperson: In Person Classes\n",
      "   Fall 2021 has 33 classes\n",
      "   Spring 2022 has 31 classes\n",
      "   Fall 2022 has 32 classes\n",
      "   Spring 2023 has 34 classes\n",
      "   Fall 2023 has 38 classes\n",
      "   Spring 2024 has 40 classes\n",
      "   Fall 2024 has 62 classes\n",
      "   Spring 2025 has 69 classes\n",
      "\n",
      "df_all_online: Online Classes\n",
      "   Fall 2021 has 155 classes\n",
      "   Spring 2022 has 143 classes\n",
      "   Fall 2022 has 138 classes\n",
      "   Spring 2023 has 149 classes\n",
      "   Fall 2023 has 157 classes\n",
      "   Spring 2024 has 166 classes\n",
      "   Fall 2024 has 151 classes\n",
      "   Spring 2025 has 161 classes\n"
     ]
    }
   ],
   "source": [
    "#Totals by Session\n",
    "for df_semester, df in dfs_all_inperson_online.items():\n",
    "    # Separate inperson/online within our new dictionary\n",
    "    modality = \"In Person Classes\" if \"inperson\" in df_semester else \"Online Classes\"\n",
    "\n",
    "    # Group by Term (semester) & count\n",
    "    term_counts = df.groupby(\"Term\").size()\n",
    "\n",
    "    # Function: sort by semester order\n",
    "    # Using key=lambda x: for each tuples (term + count), sort by applying function to x[0] term first\n",
    "    sorted_term_counts = sorted(term_counts.items(), key=lambda x: semester_order_func(x[0]))\n",
    "\n",
    "    print(f\"\\n{df_semester}: {modality}\")\n",
    "    for term, count in sorted_term_counts:\n",
    "        print(f\"   {term} has {count} classes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online/Live Online by Semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall 2021: 155 total classes, 142 Fully Online, and 13 Live Online\n",
      "Spring 2022: 143 total classes, 142 Fully Online, and 1 Live Online\n",
      "Fall 2022: 138 total classes, 138 Fully Online, and 0 Live Online\n",
      "Spring 2023: 149 total classes, 145 Fully Online, and 4 Live Online\n",
      "Fall 2023: 157 total classes, 153 Fully Online, and 4 Live Online\n",
      "Spring 2024: 166 total classes, 162 Fully Online, and 4 Live Online\n",
      "Fall 2024: 151 total classes, 147 Fully Online, and 4 Live Online\n",
      "Spring 2025: 161 total classes, 157 Fully Online, and 4 Live Online\n"
     ]
    }
   ],
   "source": [
    "# Get unique Term values from DF df_all_online\n",
    "terms = df_all_online[\"Term\"].unique()\n",
    "\n",
    "# For loop with our sorted function semester_order_func\n",
    "for df_semester in sorted(terms, key=semester_order_func):\n",
    "    df_term = df_all_online[df_all_online[\"Term\"] == df_semester]\n",
    "    \n",
    "    total = df_term.shape[0]\n",
    "    fully_online = (df_term[\"Facility\"] == \"Online\").sum()\n",
    "    live_online = (df_term[\"Facility\"] == \"Live Online\").sum()\n",
    "    \n",
    "    print(f\"{df_semester}: {total} total classes, {fully_online} Fully Online, and {live_online} Live Online\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>In-Person/Online by Modalities </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online/In-Person: Session (15 week vs 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online vs In-Person by Session Type (15/7): Totals\n",
      "\n",
      "df_all_inperson: Total by Session\n",
      "Session\n",
      "Regular Academic Session    339\n",
      "Name: count, dtype: int64\n",
      "\n",
      "df_all_online: Total by Session\n",
      "Session\n",
      "Regular Academic Session    635\n",
      "Seven Week - Second         298\n",
      "Seven Week - First          287\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Online vs In-Person by Session Type (15/7): Totals\")\n",
    "\n",
    "for name, df in dfs_all_inperson_online.items():\n",
    "    print(f\"\\n{name}: Total by Session\")\n",
    "    session_counts = df[\"Session\"].value_counts(dropna=False)\n",
    "    print(session_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online vs In-Person by Session Type (15/7) & Semester\n",
      "\n",
      "df_all_inperson: Session by Semester (Term)\n",
      "Session      Regular Academic Session\n",
      "Term                                 \n",
      "Fall 2021                          33\n",
      "Spring 2022                        31\n",
      "Fall 2022                          32\n",
      "Spring 2023                        34\n",
      "Fall 2023                          38\n",
      "Spring 2024                        40\n",
      "Fall 2024                          62\n",
      "Spring 2025                        69\n",
      "\n",
      "df_all_online: Session by Semester (Term)\n",
      "Session      Regular Academic Session  Seven Week - First  Seven Week - Second\n",
      "Term                                                                          \n",
      "Fall 2021                          97                  32                   26\n",
      "Spring 2022                        78                  27                   38\n",
      "Fall 2022                          75                  30                   33\n",
      "Spring 2023                        77                  34                   38\n",
      "Fall 2023                          82                  38                   37\n",
      "Spring 2024                        80                  43                   43\n",
      "Fall 2024                          71                  42                   38\n",
      "Spring 2025                        75                  41                   45\n"
     ]
    }
   ],
   "source": [
    "print(\"Online vs In-Person by Session Type (15/7) & Semester\")\n",
    "\n",
    "for df_semester, df in dfs_all_inperson_online.items():\n",
    "    print(f\"\\n{df_semester}: Session by Semester (Term)\")\n",
    "   \n",
    "    # Group by \"Term\" and \"Session Grouped\"; .size() count the rows; unstack() turn into a DF\n",
    "    session_by_term = df.groupby([\"Term\", \"Session\"]).size().unstack(fill_value=0)\n",
    "   \n",
    "    # Order semesters with function semester_order_func; .loc[] to return a DF\n",
    "    session_by_term = session_by_term.loc[sorted(session_by_term.index, key=semester_order_func)]\n",
    "    print(session_by_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-week: combine 7W1 and 7W2 into 1 term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online Classes by 15/7 Week, Totalling both 7-Week Sessions\n",
      "\n",
      "Totals in Dataset:\n",
      "Session Grouped\n",
      "Regular Academic Session    635\n",
      "Seven Week Combined         585\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Session by Semester (Term):\n",
      "Session Grouped  Regular Academic Session  Seven Week Combined\n",
      "Term                                                          \n",
      "Fall 2021                              97                   58\n",
      "Spring 2022                            78                   65\n",
      "Fall 2022                              75                   63\n",
      "Spring 2023                            77                   72\n",
      "Fall 2023                              82                   75\n",
      "Spring 2024                            80                   86\n",
      "Fall 2024                              71                   80\n",
      "Spring 2025                            75                   86\n"
     ]
    }
   ],
   "source": [
    "# New DF df_online_7week, to not confuse with df_all_online\n",
    "df_online_7week = df_all_online.copy()\n",
    "\n",
    "# Group \"Seven Week - First\" and \"Seven Week - Second\" into a single \"Seven Week Combined\"\n",
    "df_online_7week[\"Session Grouped\"] = df_online_7week[\"Session\"].replace({\n",
    "    \"Seven Week - First\": \"Seven Week Combined\",\n",
    "    \"Seven Week - Second\": \"Seven Week Combined\"})\n",
    "\n",
    "print(\"Online Classes by 15/7 Week, Totalling both 7-Week Sessions\")\n",
    "\n",
    "# Total counts by session type (15/7)\n",
    "print(\"\\nTotals in Dataset:\")\n",
    "session_counts = df_online_7week[\"Session Grouped\"].value_counts()\n",
    "print(session_counts)\n",
    "\n",
    "# Totals by Session type & by Term\n",
    "print(\"\\nSession by Semester (Term):\")\n",
    "session_by_term = df_online_7week.groupby([\"Term\", \"Session Grouped\"]).size().unstack(fill_value=0)\n",
    "session_by_term = session_by_term.loc[sorted(session_by_term.index, key=semester_order_func)] # Run semester_order_func to sort\n",
    "print(session_by_term)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online/In-Person by Meeting Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online vs In-Person by Meeting Days\n",
      "\n",
      "df_all_inperson: Total by Meeting Days\n",
      "Meeting Days\n",
      "TR    181\n",
      "MW     75\n",
      "M      34\n",
      "F      33\n",
      "W      10\n",
      "-       5\n",
      "T       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "df_all_inperson: Meeting Days by Semester (Term)\n",
      "Meeting Days  -   F  M  MW  T  TR  W\n",
      "Term                                \n",
      "Fall 2021     0   0  0   8  0  25  0\n",
      "Spring 2022   0   2  5   5  0  19  0\n",
      "Fall 2022     0   3  3   3  0  23  0\n",
      "Spring 2023   0   2  5   7  0  19  1\n",
      "Fall 2023     0   2  4  10  0  21  1\n",
      "Spring 2024   0   3  5  10  0  21  1\n",
      "Fall 2024     2  11  5  17  0  24  3\n",
      "Spring 2025   3  10  7  15  1  29  4\n",
      "\n",
      "df_all_online: Total by Meeting Days\n",
      "Meeting Days\n",
      "-     1186\n",
      "TR      24\n",
      "MW       4\n",
      "R        3\n",
      "W        2\n",
      "F        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "df_all_online: Meeting Days by Semester (Term)\n",
      "Meeting Days    -  F  MW  R  TR  W\n",
      "Term                              \n",
      "Fall 2021     142  1   4  3   3  2\n",
      "Spring 2022   142  0   0  0   1  0\n",
      "Fall 2022     138  0   0  0   0  0\n",
      "Spring 2023   145  0   0  0   4  0\n",
      "Fall 2023     153  0   0  0   4  0\n",
      "Spring 2024   162  0   0  0   4  0\n",
      "Fall 2024     147  0   0  0   4  0\n",
      "Spring 2025   157  0   0  0   4  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Online vs In-Person by Meeting Days\")\n",
    "\n",
    "for name, df in dfs_all_inperson_online.items():\n",
    "    # Print Online/In-Person Totals by Meeting Days\n",
    "    print(f\"\\n{name}: Total by Meeting Days\")\n",
    "    meeting_days_total = df[\"Meeting Days\"].value_counts(dropna=False)\n",
    "    print(meeting_days_total)\n",
    "    \n",
    "    # Print Online/In-Person Totals by Meeting Days & by Semester (Term) \n",
    "    print(f\"\\n{name}: Meeting Days by Semester (Term)\")\n",
    "    # Group by Term & Meeting Days; .size() count the rows; unstack() turn into a DF\n",
    "    meeting_days_by_term = df.groupby([\"Term\", \"Meeting Days\"]).size().unstack(fill_value=0)\n",
    "    meeting_days_by_term = meeting_days_by_term.loc[sorted(meeting_days_by_term.index, key=semester_order_func)]\n",
    "    print(meeting_days_by_term)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online/Live Online by Days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split df_all_online into Online/Live Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_online_fully = df_all_online[df_all_online[\"Facility\"] == \"Online\"].copy()\n",
    "df_all_online_live = df_all_online[df_all_online[\"Facility\"] == \"Live Online\"].copy()\n",
    "\n",
    "dfs_online_vs_live = {\n",
    "    \"df_all_online_fully\": df_all_online_fully,\n",
    "    \"df_all_online_live\": df_all_online_live\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online vs Live Online - Meeting Days\n",
      "\n",
      "df_all_online_fully: Total by Meeting Days\n",
      "Meeting Days\n",
      "-    1186\n",
      "Name: count, dtype: int64\n",
      "\n",
      "df_all_online_fully: Meeting Days by Semester (Term)\n",
      "Meeting Days    -\n",
      "Term             \n",
      "Fall 2021     142\n",
      "Spring 2022   142\n",
      "Fall 2022     138\n",
      "Spring 2023   145\n",
      "Fall 2023     153\n",
      "Spring 2024   162\n",
      "Fall 2024     147\n",
      "Spring 2025   157\n",
      "\n",
      "df_all_online_live: Total by Meeting Days\n",
      "Meeting Days\n",
      "TR    24\n",
      "MW     4\n",
      "R      3\n",
      "W      2\n",
      "F      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "df_all_online_live: Meeting Days by Semester (Term)\n",
      "Meeting Days  F  MW  R  TR  W\n",
      "Term                         \n",
      "Fall 2021     1   4  3   3  2\n",
      "Spring 2022   0   0  0   1  0\n",
      "Spring 2023   0   0  0   4  0\n",
      "Fall 2023     0   0  0   4  0\n",
      "Spring 2024   0   0  0   4  0\n",
      "Fall 2024     0   0  0   4  0\n",
      "Spring 2025   0   0  0   4  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Online vs Live Online - Meeting Days\")\n",
    "\n",
    "for name, df in dfs_online_vs_live.items():\n",
    "    # Online vs Live Online Totals by Meeting Days\n",
    "    print(f\"\\n{name}: Total by Meeting Days\")\n",
    "    meeting_days_total = df[\"Meeting Days\"].value_counts(dropna=False)\n",
    "    print(meeting_days_total)\n",
    "\n",
    "    # Online vs Live Online Totals by Meeting Days & by Semester (Term)\n",
    "    print(f\"\\n{name}: Meeting Days by Semester (Term)\")\n",
    "    meeting_days_by_term = df.groupby([\"Term\", \"Meeting Days\"]).size().unstack(fill_value=0)\n",
    "    meeting_days_by_term = meeting_days_by_term.loc[sorted(meeting_days_by_term.index, key=semester_order_func)]\n",
    "    print(meeting_days_by_term)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online/In-Person by Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online/In-Person by Component\n",
      "\n",
      "df_all_inperson: Total by Component\n",
      "Component\n",
      "Lecture       266\n",
      "Discussion     67\n",
      "Colloquium      6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "df_all_inperson: Component by Semester (Term)\n",
      "Component    Colloquium  Discussion  Lecture\n",
      "Term                                        \n",
      "Fall 2021             0           0       33\n",
      "Spring 2022           1           6       24\n",
      "Fall 2022             0           6       26\n",
      "Spring 2023           2           6       26\n",
      "Fall 2023             0           6       32\n",
      "Spring 2024           1           6       33\n",
      "Fall 2024             1          18       43\n",
      "Spring 2025           1          19       49\n",
      "\n",
      "df_all_online: Total by Component\n",
      "Component\n",
      "Lecture       1104\n",
      "Discussion     115\n",
      "Colloquium       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "df_all_online: Component by Semester (Term)\n",
      "Component    Colloquium  Discussion  Lecture\n",
      "Term                                        \n",
      "Fall 2021             1          27      127\n",
      "Spring 2022           0          15      128\n",
      "Fall 2022             0          14      124\n",
      "Spring 2023           0          15      134\n",
      "Fall 2023             0          15      142\n",
      "Spring 2024           0          15      151\n",
      "Fall 2024             0           8      143\n",
      "Spring 2025           0           6      155\n"
     ]
    }
   ],
   "source": [
    "print(\"Online/In-Person by Component\")\n",
    "\n",
    "for name, df in dfs_all_inperson_online.items():\n",
    "    # Print Online/In-Person Totals by Component\n",
    "    print(f\"\\n{name}: Total by Component\")\n",
    "    component_total = df[\"Component\"].value_counts(dropna=False)\n",
    "    print(component_total)\n",
    "\n",
    "    # Print Online/In-Person Totals by Component & by Semester (Term)\n",
    "    print(f\"\\n{name}: Component by Semester (Term)\")\n",
    "    component_by_term = df.groupby([\"Term\", \"Component\"]).size().unstack(fill_value=0)\n",
    "    component_by_term = component_by_term.loc[sorted(component_by_term.index, key=semester_order_func)]\n",
    "    print(component_by_term)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Modality: 15-week vs 7-week </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15/7 totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modality Breakdown by Session Type (15-week vs 7-week)\n",
      "\n",
      "df_all: Courses by Session\n",
      "Session\n",
      "Regular Academic Session    974\n",
      "Seven Week - Second         298\n",
      "Seven Week - First          287\n",
      "Name: count, dtype: int64\n",
      "\n",
      "df_fall_all: Courses by Session\n",
      "Session\n",
      "Regular Academic Session    490\n",
      "Seven Week - First          142\n",
      "Seven Week - Second         134\n",
      "Name: count, dtype: int64\n",
      "\n",
      "df_spring_all: Courses by Session\n",
      "Session\n",
      "Regular Academic Session    484\n",
      "Seven Week - Second         164\n",
      "Seven Week - First          145\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Modality Breakdown by Session Type (15-week vs 7-week)\")\n",
    "\n",
    "for name, df in dfs_all.items():\n",
    "    print(f\"\\n{name}: Courses by Session\")\n",
    "    # 15-week vs. 7-week Totals\n",
    "    session_counts = df[\"Session\"].value_counts(dropna=False)\n",
    "    print(session_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15/7 by Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/7 Course Counts by Term\n",
      "Session      Regular Academic Session  Seven Week - First  Seven Week - Second\n",
      "Term                                                                          \n",
      "Fall 2021                         130                  32                   26\n",
      "Spring 2022                       109                  27                   38\n",
      "Fall 2022                         107                  30                   33\n",
      "Spring 2023                       111                  34                   38\n",
      "Fall 2023                         120                  38                   37\n",
      "Spring 2024                       120                  43                   43\n",
      "Fall 2024                         133                  42                   38\n",
      "Spring 2025                       144                  41                   45\n"
     ]
    }
   ],
   "source": [
    "print(\"15/7 Course Counts by Term\")\n",
    "\n",
    "# Group by Session and Term; Sort\n",
    "session_by_term = df_all.groupby([\"Term\", \"Session\"]).size().unstack(fill_value=0)\n",
    "# Run semester_order_func to sort\n",
    "session_by_term = session_by_term.loc[sorted(session_by_term.index, key=semester_order_func)]\n",
    "print(session_by_term)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 15/7 by Modalities </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15/7 by Days Scheduled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/7 by Days Scheduled, Totals:\n",
      "\n",
      "df_all:\n",
      "Meeting Days                -   F   M  MW  R  T   TR   W\n",
      "Session                                                 \n",
      "Regular Academic Session  606  34  34  79  3  1  205  12\n",
      "Seven Week - First        287   0   0   0  0  0    0   0\n",
      "Seven Week - Second       298   0   0   0  0  0    0   0\n",
      "\n",
      "df_fall_all:\n",
      "Meeting Days                -   F   M  MW  R   TR  W\n",
      "Session                                             \n",
      "Regular Academic Session  306  17  12  42  3  104  6\n",
      "Seven Week - First        142   0   0   0  0    0  0\n",
      "Seven Week - Second       134   0   0   0  0    0  0\n",
      "\n",
      "df_spring_all:\n",
      "Meeting Days                -   F   M  MW  T   TR  W\n",
      "Session                                             \n",
      "Regular Academic Session  300  17  22  37  1  101  6\n",
      "Seven Week - First        145   0   0   0  0    0  0\n",
      "Seven Week - Second       164   0   0   0  0    0  0\n"
     ]
    }
   ],
   "source": [
    "print(\"15/7 by Days Scheduled, Totals:\")\n",
    "\n",
    "for name, df in dfs_all.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    summary = df.groupby([\"Session\", \"Meeting Days\"]).size().unstack(fill_value=0)\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/7 by Days Scheduled & Semester\n",
      "Meeting Days                           -   F  M  MW  R  T  TR  W\n",
      "Term        Session                                             \n",
      "Fall 2021   Regular Academic Session  84   1  0  12  3  0  28  2\n",
      "            Seven Week - First        32   0  0   0  0  0   0  0\n",
      "            Seven Week - Second       26   0  0   0  0  0   0  0\n",
      "Spring 2022 Regular Academic Session  77   2  5   5  0  0  20  0\n",
      "            Seven Week - First        27   0  0   0  0  0   0  0\n",
      "            Seven Week - Second       38   0  0   0  0  0   0  0\n",
      "Fall 2022   Regular Academic Session  75   3  3   3  0  0  23  0\n",
      "            Seven Week - First        30   0  0   0  0  0   0  0\n",
      "            Seven Week - Second       33   0  0   0  0  0   0  0\n",
      "Spring 2023 Regular Academic Session  73   2  5   7  0  0  23  1\n",
      "            Seven Week - First        34   0  0   0  0  0   0  0\n",
      "            Seven Week - Second       38   0  0   0  0  0   0  0\n",
      "Fall 2023   Regular Academic Session  78   2  4  10  0  0  25  1\n",
      "            Seven Week - First        38   0  0   0  0  0   0  0\n",
      "            Seven Week - Second       37   0  0   0  0  0   0  0\n",
      "Spring 2024 Regular Academic Session  76   3  5  10  0  0  25  1\n",
      "            Seven Week - First        43   0  0   0  0  0   0  0\n",
      "            Seven Week - Second       43   0  0   0  0  0   0  0\n",
      "Fall 2024   Regular Academic Session  69  11  5  17  0  0  28  3\n",
      "            Seven Week - First        42   0  0   0  0  0   0  0\n",
      "            Seven Week - Second       38   0  0   0  0  0   0  0\n",
      "Spring 2025 Regular Academic Session  74  10  7  15  0  1  33  4\n",
      "            Seven Week - First        41   0  0   0  0  0   0  0\n",
      "            Seven Week - Second       45   0  0   0  0  0   0  0\n"
     ]
    }
   ],
   "source": [
    "print(\"15/7 by Days Scheduled & Semester\")\n",
    "\n",
    "# Group by Term (semester), Session (15/7), and Meeting Days\n",
    "meeting_days_summary = df_all.groupby([\"Term\", \"Session\", \"Meeting Days\"]).size()\n",
    "\n",
    "# Turn Meeting Days (meeting_days_summary) into Columns for cleaner output; sort\n",
    "session_term_days = meeting_days_summary.unstack(fill_value=0)\n",
    "\n",
    "# Sort with semester_order_func: multi-index\n",
    "# key = lambda x again because this one is multi-index\n",
    "session_term_days = session_term_days.loc[sorted(session_term_days.index, key=lambda x: semester_order_func(x[0]))]\n",
    "print(session_term_days)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15/7 by Days Scheduled & Semester -- totaling the two Seven Weeks into 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/7 by Days Scheduled & Semester - Combining 7 week sessions\n",
      "Meeting Days                           -   F  M  MW  R  T  TR  W\n",
      "Term        Session Grouped                                     \n",
      "Fall 2021   Regular Academic Session  84   1  0  12  3  0  28  2\n",
      "            Seven Week Combined       58   0  0   0  0  0   0  0\n",
      "Spring 2022 Regular Academic Session  77   2  5   5  0  0  20  0\n",
      "            Seven Week Combined       65   0  0   0  0  0   0  0\n",
      "Fall 2022   Regular Academic Session  75   3  3   3  0  0  23  0\n",
      "            Seven Week Combined       63   0  0   0  0  0   0  0\n",
      "Spring 2023 Regular Academic Session  73   2  5   7  0  0  23  1\n",
      "            Seven Week Combined       72   0  0   0  0  0   0  0\n",
      "Fall 2023   Regular Academic Session  78   2  4  10  0  0  25  1\n",
      "            Seven Week Combined       75   0  0   0  0  0   0  0\n",
      "Spring 2024 Regular Academic Session  76   3  5  10  0  0  25  1\n",
      "            Seven Week Combined       86   0  0   0  0  0   0  0\n",
      "Fall 2024   Regular Academic Session  69  11  5  17  0  0  28  3\n",
      "            Seven Week Combined       80   0  0   0  0  0   0  0\n",
      "Spring 2025 Regular Academic Session  74  10  7  15  0  1  33  4\n",
      "            Seven Week Combined       86   0  0   0  0  0   0  0\n"
     ]
    }
   ],
   "source": [
    "print(\"15/7 by Days Scheduled & Semester - Combining 7 week sessions\")\n",
    "\n",
    "# Create a new dataframe to avoid directly modifying df_all \n",
    "# Last time we did this, it was building off the df_all_online DF, so we're doing it again on df_all\n",
    "df_all_7week = df_all.copy()\n",
    "\n",
    "# Group \"Seven Week - First\" and \"Seven Week - Second\" into a single \"Seven Week Combined\"\n",
    "df_all_7week[\"Session Grouped\"] = df_all_7week[\"Session\"].replace({\n",
    "    \"Seven Week - First\": \"Seven Week Combined\", \n",
    "    \"Seven Week - Second\": \"Seven Week Combined\"})\n",
    "\n",
    "# Group by Term, Session Grouped (15/7), and Meeting Days\n",
    "meeting_days_summary = df_all_7week.groupby([\"Term\", \"Session Grouped\", \"Meeting Days\"]).size()\n",
    "\n",
    "# Turn Meeting Days into columns for cleaner output\n",
    "session_term_days = meeting_days_summary.unstack(fill_value=0)\n",
    "\n",
    "# Sort the semesters semester_order_func \n",
    "# MultiIndex: Term + Session - needs key = lambda x again\n",
    "session_term_days = session_term_days.loc[sorted(session_term_days.index, key=lambda x: semester_order_func(x[0]))]\n",
    "\n",
    "print(session_term_days)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15/7 by Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/7 by Component: Totals\n",
      "Component                 Colloquium  Discussion  Lecture\n",
      "Session                                                  \n",
      "Regular Academic Session           7         181      786\n",
      "Seven Week - First                 0           1      286\n",
      "Seven Week - Second                0           0      298\n",
      "\n",
      "15/7 by Component: Totals by Semester\n",
      "Component                             Colloquium  Discussion  Lecture\n",
      "Term        Session                                                  \n",
      "Fall 2021   Regular Academic Session           1          27      102\n",
      "            Seven Week - First                 0           0       32\n",
      "            Seven Week - Second                0           0       26\n",
      "Spring 2022 Regular Academic Session           1          21       87\n",
      "            Seven Week - First                 0           0       27\n",
      "            Seven Week - Second                0           0       38\n",
      "Fall 2022   Regular Academic Session           0          20       87\n",
      "            Seven Week - First                 0           0       30\n",
      "            Seven Week - Second                0           0       33\n",
      "Spring 2023 Regular Academic Session           2          21       88\n",
      "            Seven Week - First                 0           0       34\n",
      "            Seven Week - Second                0           0       38\n",
      "Fall 2023   Regular Academic Session           0          21       99\n",
      "            Seven Week - First                 0           0       38\n",
      "            Seven Week - Second                0           0       37\n",
      "Spring 2024 Regular Academic Session           1          21       98\n",
      "            Seven Week - First                 0           0       43\n",
      "            Seven Week - Second                0           0       43\n",
      "Fall 2024   Regular Academic Session           1          25      107\n",
      "            Seven Week - First                 0           1       41\n",
      "            Seven Week - Second                0           0       38\n",
      "Spring 2025 Regular Academic Session           1          25      118\n",
      "            Seven Week - First                 0           0       41\n",
      "            Seven Week - Second                0           0       45\n"
     ]
    }
   ],
   "source": [
    "print(\"15/7 by Component: Totals\")\n",
    "\n",
    "# Total counts: Session × Component\n",
    "component_total = df_all.groupby([\"Session\", \"Component\"]).size().unstack(fill_value=0)\n",
    "print(component_total)\n",
    "\n",
    "print(\"\\n15/7 by Component: Totals by Semester\")\n",
    "\n",
    "# By Term: Term × Session × Component\n",
    "component_by_term = df_all.groupby([\"Term\", \"Session\", \"Component\"]).size().unstack(fill_value=0)\n",
    "\n",
    "# Sort - multi-index again (needs key=lambda x)\n",
    "component_by_term = component_by_term.loc[sorted(component_by_term.index, key=lambda x: semester_order_func(x[0]))]\n",
    "\n",
    "print(component_by_term)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Modality: Days Scheduled </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Days Scheduled - Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modality: Days Scheduled Totals\n",
      "\n",
      "df_all:\n",
      "Meeting Days\n",
      "-     1191\n",
      "TR     205\n",
      "MW      79\n",
      "F       34\n",
      "M       34\n",
      "W       12\n",
      "R        3\n",
      "T        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "df_fall_all:\n",
      "Meeting Days\n",
      "-     582\n",
      "TR    104\n",
      "MW     42\n",
      "F      17\n",
      "M      12\n",
      "W       6\n",
      "R       3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "df_spring_all:\n",
      "Meeting Days\n",
      "-     609\n",
      "TR    101\n",
      "MW     37\n",
      "M      22\n",
      "F      17\n",
      "W       6\n",
      "T       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Modality: Days Scheduled Totals\")\n",
    "\n",
    "for name, df in dfs_all.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(df[\"Meeting Days\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Days Scheduled - Totals by Semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days Scheduled by Semester\n",
      "Meeting Days    -   F  M  MW  R  T  TR  W\n",
      "Term                                     \n",
      "Fall 2021     142   1  0  12  3  0  28  2\n",
      "Spring 2022   142   2  5   5  0  0  20  0\n",
      "Fall 2022     138   3  3   3  0  0  23  0\n",
      "Spring 2023   145   2  5   7  0  0  23  1\n",
      "Fall 2023     153   2  4  10  0  0  25  1\n",
      "Spring 2024   162   3  5  10  0  0  25  1\n",
      "Fall 2024     149  11  5  17  0  0  28  3\n",
      "Spring 2025   160  10  7  15  0  1  33  4\n"
     ]
    }
   ],
   "source": [
    "#Days Scheduled - Totals by Semester\n",
    "\n",
    "#Group by Term/Days & run semester_order_func\n",
    "days_scheduled_semester = df_all.groupby([\"Term\", \"Meeting Days\"]).size().unstack(fill_value=0)\n",
    "days_scheduled_semester = days_scheduled_semester.loc[sorted(days_scheduled_semester.index, key=semester_order_func)]\n",
    "\n",
    "print(\"Days Scheduled by Semester\")\n",
    "print(days_scheduled_semester)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Days Scheduled by Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days Scheduled by Component: Totals\n",
      "Meeting Days     -   F   M  MW  R  T   TR  W\n",
      "Component                                   \n",
      "Colloquium       0   0   5   1  0  0    1  0\n",
      "Discussion     109  33  29   0  3  0    0  8\n",
      "Lecture       1082   1   0  78  0  1  204  4\n",
      "\n",
      "Days Scheduled by Component: Totals\n",
      "Meeting Days              -   F  M  MW  R  T  TR  W\n",
      "Term        Component                              \n",
      "Fall 2021   Colloquium    0   0  0   0  0  0   1  0\n",
      "            Discussion   21   1  0   0  3  0   0  2\n",
      "            Lecture     121   0  0  12  0  0  27  0\n",
      "Spring 2022 Colloquium    0   0  1   0  0  0   0  0\n",
      "            Discussion   15   2  4   0  0  0   0  0\n",
      "            Lecture     127   0  0   5  0  0  20  0\n",
      "Fall 2022   Discussion   14   3  3   0  0  0   0  0\n",
      "            Lecture     124   0  0   3  0  0  23  0\n",
      "Spring 2023 Colloquium    0   0  1   1  0  0   0  0\n",
      "            Discussion   15   2  4   0  0  0   0  0\n",
      "            Lecture     130   0  0   6  0  0  23  1\n",
      "Fall 2023   Discussion   15   2  4   0  0  0   0  0\n",
      "            Lecture     138   0  0  10  0  0  25  1\n",
      "Spring 2024 Colloquium    0   0  1   0  0  0   0  0\n",
      "            Discussion   15   2  4   0  0  0   0  0\n",
      "            Lecture     147   1  0  10  0  0  25  1\n",
      "Fall 2024   Colloquium    0   0  1   0  0  0   0  0\n",
      "            Discussion    8  11  4   0  0  0   0  3\n",
      "            Lecture     141   0  0  17  0  0  28  0\n",
      "Spring 2025 Colloquium    0   0  1   0  0  0   0  0\n",
      "            Discussion    6  10  6   0  0  0   0  3\n",
      "            Lecture     154   0  0  15  0  1  33  1\n"
     ]
    }
   ],
   "source": [
    "# Days by Component - Totals\n",
    "\n",
    "# Group by Component and Meeting Days\n",
    "days_by_component_total = df_all.groupby([\"Component\", \"Meeting Days\"]).size().unstack(fill_value=0)\n",
    "print(\"Days Scheduled by Component: Totals\")\n",
    "print(days_by_component_total)\n",
    "\n",
    "# Group by Term, Component, and Meeting Days\n",
    "days_by_component_term = df_all.groupby([\"Term\", \"Component\", \"Meeting Days\"]).size().unstack(fill_value=0)\n",
    "# Sort - multi-index again (key=lambda x)\n",
    "days_by_component_term = days_by_component_term.loc[sorted(days_by_component_term.index, key=lambda x: semester_order_func(x[0]))]\n",
    "print(\"\\nDays Scheduled by Component: Totals\")\n",
    "print(days_by_component_term)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Modality: Time of Day </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of Day - Counts by Start Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by Meeting Time Start\n",
      "Meeting Time Start\n",
      "00:00:00    1191\n",
      "08:00:00       7\n",
      "09:00:00       6\n",
      "09:30:00      14\n",
      "10:00:00      14\n",
      "11:00:00      95\n",
      "12:00:00       7\n",
      "12:30:00      78\n",
      "13:00:00      13\n",
      "14:00:00      54\n",
      "15:00:00      13\n",
      "15:30:00      58\n",
      "16:00:00       5\n",
      "17:30:00       4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Meeting Time Start - Totals\n",
    "start_time_counts = df_all[\"Meeting Time Start\"].value_counts(dropna=False).sort_index()\n",
    "\n",
    "print(\"Counts by Meeting Time Start\")\n",
    "print(start_time_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of Day - Counts by Semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meeting Start Time Counts by Semester\n",
      "Meeting Time Start  00:00:00  08:00:00  09:00:00  09:30:00  10:00:00  \\\n",
      "Term                                                                   \n",
      "Fall 2021                142         0         0         7         0   \n",
      "Spring 2022              142         1         0         0         2   \n",
      "Fall 2022                138         1         1         0         1   \n",
      "Spring 2023              145         1         0         0         2   \n",
      "Fall 2023                153         1         0         0         2   \n",
      "Spring 2024              162         1         0         0         3   \n",
      "Fall 2024                149         1         2         3         2   \n",
      "Spring 2025              160         1         3         4         2   \n",
      "\n",
      "Meeting Time Start  11:00:00  12:00:00  12:30:00  13:00:00  14:00:00  \\\n",
      "Term                                                                   \n",
      "Fall 2021                 10         1         9         1         8   \n",
      "Spring 2022                9         1         6         1         6   \n",
      "Fall 2022                  7         0         9         1         3   \n",
      "Spring 2023                6         1         9         1         8   \n",
      "Fall 2023                  9         1        11         1         6   \n",
      "Spring 2024               11         1        11         1         6   \n",
      "Fall 2024                 23         1         9         3         9   \n",
      "Spring 2025               20         1        14         4         8   \n",
      "\n",
      "Meeting Time Start  15:00:00  15:30:00  16:00:00  17:30:00  \n",
      "Term                                                        \n",
      "Fall 2021                  3         5         1         1  \n",
      "Spring 2022                1         4         0         1  \n",
      "Fall 2022                  1         7         1         0  \n",
      "Spring 2023                2         7         1         0  \n",
      "Fall 2023                  0         8         2         1  \n",
      "Spring 2024                1         9         0         0  \n",
      "Fall 2024                  2         8         0         1  \n",
      "Spring 2025                3        10         0         0  \n"
     ]
    }
   ],
   "source": [
    "# Meeting Time Start totals by Term; run semester_order_func\n",
    "start_times_semester = df_all.groupby([\"Term\", \"Meeting Time Start\"]).size().unstack(fill_value=0)\n",
    "start_times_semester = start_times_semester.loc[sorted(start_times_semester.index, key=semester_order_func)]\n",
    "\n",
    "print(\"Meeting Start Time Counts by Semester\")\n",
    "print(start_times_semester)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Time of Day Function #1: </h3> break up by morning, midday, afternoon, late afternoon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First - Convert \"Meeting Time Start & \"Meeting Time End\" to datetime (HH:MM:SS) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new DF\n",
    "df_all_times = df_all.copy()\n",
    "\n",
    "# Columns to convert\n",
    "time_columns = [\"Meeting Time Start\", \"Meeting Time End\"]\n",
    "\n",
    "import datetime\n",
    "for col in time_columns:\n",
    "    if col in df_all_times.columns:\n",
    "        # Convert to dt.time in the format HH:MM:SS\n",
    "        df_all_times[col] = pd.to_datetime(df_all_times[col], format=\"%H:%M:%S\", errors=\"coerce\").dt.time\n",
    "\n",
    "# Check for conversion - still says \"object\" but at least it's a datetime.time object\n",
    "#print(df_all_times.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of Day function #1: assign_time_slot \n",
    "\n",
    "morning (through 10am), midday (past 10, through 1pm), afternoon (past 1pm, through 3:30pm), and late afternoon (after 3:30pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for labeling time slots\n",
    "def assign_time_slot(t):\n",
    "    if pd.isnull(t) or t == datetime.time(0, 0):\n",
    "        return \"NoTime\"\n",
    "    elif t <= datetime.time(10, 0):\n",
    "        return \"Morning\"\n",
    "    elif t <= datetime.time(13, 0):\n",
    "        return \"Midday\"\n",
    "    elif t <= datetime.time(15, 30):\n",
    "        return \"Afternoon\"\n",
    "    else:\n",
    "        return \"Late Afternoon\"\n",
    "\n",
    "# Apply function to create new column\n",
    "df_all_times[\"Time Slot\"] = df_all_times[\"Meeting Time Start\"].apply(assign_time_slot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of Day: Total Counts & Total Counts by Semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totals by Time Slot\n",
      "Time Slot\n",
      "Morning             41\n",
      "Midday             193\n",
      "Afternoon          125\n",
      "Late Afternoon       9\n",
      "NoTime            1191\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Totals by Time Slot & Semester\n",
      "Time Slot    Morning  Midday  Afternoon  Late Afternoon  NoTime\n",
      "Term                                                           \n",
      "Fall 2021          7      21         16               2     142\n",
      "Spring 2022        3      17         11               1     142\n",
      "Fall 2022          3      17         11               1     138\n",
      "Spring 2023        3      17         17               1     145\n",
      "Fall 2023          3      22         14               3     153\n",
      "Spring 2024        4      24         16               0     162\n",
      "Fall 2024          8      36         19               1     149\n",
      "Spring 2025       10      39         21               0     160\n"
     ]
    }
   ],
   "source": [
    "# Print times in Order\n",
    "ordered_time = [\"Morning\", \"Midday\", \"Afternoon\", \"Late Afternoon\", \"NoTime\"]\n",
    "\n",
    "# Totals by Time Slot\n",
    "# Get value counts, then reindex to your order (ordered_time)\n",
    "time_slot_total = df_all_times[\"Time Slot\"].value_counts(dropna=False).reindex(ordered_time, fill_value=0)\n",
    "\n",
    "print(\"Totals by Time Slot\")\n",
    "print(time_slot_total)\n",
    "\n",
    "# Time Slot Totals by Semester - .groupby([\"Term\", \"Time Slot\"])\n",
    "time_slot_semester = df_all_times.groupby([\"Term\", \"Time Slot\"]).size().unstack(fill_value=0)\n",
    "time_slot_semester = time_slot_semester[ordered_time] # Reorder time slots to ordered_time\n",
    "time_slot_semester = time_slot_semester.loc[sorted(time_slot_semester.index, key=semester_order_func)] # Semesters in order\n",
    "\n",
    "print(\"\\nTotals by Time Slot & Semester\")\n",
    "print(time_slot_semester)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Time of Day Function #2: 3 times of day</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morning: before 11. Midday: 11 through before 2. Afternoon: 2 & after\n",
    "def assign_time_slot_v2(t):\n",
    "    if pd.isnull(t) or t == datetime.time(0, 0):\n",
    "        return \"NoTime\"\n",
    "    elif t < datetime.time(11, 0):\n",
    "        return \"Morning\"\n",
    "    elif t < datetime.time(14, 0):\n",
    "        return \"Midday\"\n",
    "    else:\n",
    "        return \"Afternoon\"\n",
    "\n",
    "# New DF for our v2 Time Function\n",
    "df_all_times_v2 = df_all_times.copy()\n",
    "\n",
    "# Apply function to create new column\n",
    "df_all_times_v2[\"Time Slot\"] = df_all_times_v2[\"Meeting Time Start\"].apply(assign_time_slot_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of Day Function #2: Total Counts & Total Counts by Semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totals by Time Slot (3 time slots)\n",
      "Time Slot\n",
      "Morning        41\n",
      "Midday        193\n",
      "Afternoon     134\n",
      "NoTime       1191\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Totals by Time Slot & Semester (3 time slots)\n",
      "Time Slot    Morning  Midday  Afternoon  NoTime\n",
      "Term                                           \n",
      "Fall 2021          7      21         18     142\n",
      "Spring 2022        3      17         12     142\n",
      "Fall 2022          3      17         12     138\n",
      "Spring 2023        3      17         18     145\n",
      "Fall 2023          3      22         17     153\n",
      "Spring 2024        4      24         16     162\n",
      "Fall 2024          8      36         20     149\n",
      "Spring 2025       10      39         21     160\n"
     ]
    }
   ],
   "source": [
    "# Print times in Order\n",
    "ordered_time_v2 = [\"Morning\", \"Midday\", \"Afternoon\", \"NoTime\"]\n",
    "\n",
    "# Totals by Time Slot\n",
    "# Get value counts, then reindex to your order\n",
    "time_slot_total_v2 = df_all_times_v2[\"Time Slot\"].value_counts(dropna=False).reindex(ordered_time_v2, fill_value=0)\n",
    "\n",
    "print(\"Totals by Time Slot (3 time slots)\")\n",
    "print(time_slot_total_v2)\n",
    "\n",
    "# Time Slot Totals by Semester f\n",
    "time_slot_semester_v2 = df_all_times_v2.groupby([\"Term\", \"Time Slot\"]).size().unstack(fill_value=0)\n",
    "time_slot_semester_v2 = time_slot_semester_v2[ordered_time_v2]\n",
    "time_slot_semester_v2 = time_slot_semester_v2.loc[sorted(time_slot_semester.index, key=semester_order_func)]\n",
    "\n",
    "print(\"\\nTotals by Time Slot & Semester (3 time slots)\")\n",
    "print(time_slot_semester_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Time of Day: By Modalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of Day: In-Person/Online "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Time of Day function on In-Person/Online DFs: df_all_online & df_all_inperson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New DFs for Online/In-Person for Time Slot Analysis\n",
    "df_times_online = df_all_online.copy()\n",
    "df_times_inperson = df_all_inperson.copy()\n",
    "\n",
    "# Convert the time columns to be datetime\n",
    "for df in [df_times_online, df_times_inperson]:\n",
    "    df[\"Meeting Time Start\"] = pd.to_datetime(df[\"Meeting Time Start\"], \n",
    "                                              format=\"%H:%M:%S\", errors=\"coerce\").dt.time\n",
    "\n",
    "# Apply the Time Slot function\n",
    "df_times_online[\"Time Slot\"] = df_times_online[\"Meeting Time Start\"].apply(assign_time_slot)\n",
    "df_times_inperson[\"Time Slot\"] = df_times_inperson[\"Meeting Time Start\"].apply(assign_time_slot)\n",
    "\n",
    "dfs_times_online_inperson = {\n",
    "    \"df_times_online\": df_times_online,\n",
    "    \"df_times_inperson\": df_times_inperson\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of Day by In-Person/Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Slot Totals by Online vs In-Person\n",
      "\n",
      "df_times_online:\n",
      "Time Slot\n",
      "Morning              0\n",
      "Midday              17\n",
      "Afternoon           16\n",
      "Late Afternoon       1\n",
      "NoTime            1186\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "df_times_inperson:\n",
      "Time Slot\n",
      "Morning            41\n",
      "Midday            176\n",
      "Afternoon         109\n",
      "Late Afternoon      8\n",
      "NoTime              5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Time Slot Totals by Online vs In-Person\\n\")\n",
    "\n",
    "for df_name, df in dfs_times_online_inperson.items():\n",
    "    print(f\"{df_name}:\")\n",
    "    \n",
    "    time_modality_total = df[\"Time Slot\"].value_counts(dropna=False)\n",
    "    time_modality_total = time_modality_total.reindex(ordered_time, fill_value=0)\n",
    "    \n",
    "    print(time_modality_total)\n",
    "    print(\"\\n\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of Day by In-Person/Online & Semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Slot Totals by Online vs In-Person & Semester\n",
      "\n",
      "df_times_online:\n",
      "Time Slot    Afternoon  Late Afternoon  Midday  NoTime\n",
      "Term                                                  \n",
      "Fall 2021            6               1       6     142\n",
      "Spring 2022          0               0       1     142\n",
      "Fall 2022            0               0       0     138\n",
      "Spring 2023          2               0       2     145\n",
      "Fall 2023            2               0       2     153\n",
      "Spring 2024          2               0       2     162\n",
      "Fall 2024            2               0       2     147\n",
      "Spring 2025          2               0       2     157\n",
      "\n",
      "\n",
      "df_times_inperson:\n",
      "Time Slot    Morning  Midday  Afternoon  Late Afternoon  NoTime\n",
      "Term                                                           \n",
      "Fall 2021          7      15         10               1       0\n",
      "Spring 2022        3      16         11               1       0\n",
      "Fall 2022          3      17         11               1       0\n",
      "Spring 2023        3      15         15               1       0\n",
      "Fall 2023          3      20         12               3       0\n",
      "Spring 2024        4      22         14               0       0\n",
      "Fall 2024          8      34         17               1       2\n",
      "Spring 2025       10      37         19               0       3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Time Slot Totals by Online vs In-Person & Semester\\n\")\n",
    "\n",
    "for df_name, df in dfs_times_online_inperson.items():\n",
    "    # Group by Term and Time Slot\n",
    "    time_slot_by_term = df.groupby([\"Term\", \"Time Slot\"]).size().unstack(fill_value=0)\n",
    "    # Reorder time slots to ordered_time\n",
    "    time_slot_by_term = time_slot_by_term[ordered_time] if set(ordered_time).issubset(time_slot_by_term.columns) else time_slot_by_term\n",
    "    # Sort semesters with semester_order_func\n",
    "    time_slot_by_term = time_slot_by_term.loc[sorted(time_slot_by_term.index, key=semester_order_func)]\n",
    "\n",
    "    print(f\"{df_name}:\")\n",
    "    print(time_slot_by_term)\n",
    "    print(\"\\n\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of Day: 15-week/7-week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of Slots: 15/7 totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of Day by 15/7 Session Type\n",
      "Session         Regular Academic Session  Seven Week - First  \\\n",
      "Time Slot                                                      \n",
      "Morning                               41                   0   \n",
      "Midday                               193                   0   \n",
      "Afternoon                            125                   0   \n",
      "Late Afternoon                         9                   0   \n",
      "NoTime                               606                 287   \n",
      "\n",
      "Session         Seven Week - Second  \n",
      "Time Slot                            \n",
      "Morning                           0  \n",
      "Midday                            0  \n",
      "Afternoon                         0  \n",
      "Late Afternoon                    0  \n",
      "NoTime                          298  \n"
     ]
    }
   ],
   "source": [
    "time_session_totals = df_all_times.groupby([\"Time Slot\", \"Session\"]).size().unstack(fill_value=0) # group\n",
    "time_session_totals = time_session_totals.reindex(ordered_time) # order time slots ordered_time\n",
    "\n",
    "print(\"Time of Day by 15/7 Session Type\")\n",
    "print(time_session_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Slots by 15/7 and Semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Slot Totals by 15/7 Week & Semester\n",
      "Session                     Regular Academic Session  Seven Week - First  \\\n",
      "Time Slot      Term                                                        \n",
      "Morning        Fall 2021                           7                   0   \n",
      "               Spring 2022                         3                   0   \n",
      "               Fall 2022                           3                   0   \n",
      "               Spring 2023                         3                   0   \n",
      "               Fall 2023                           3                   0   \n",
      "               Spring 2024                         4                   0   \n",
      "               Fall 2024                           8                   0   \n",
      "               Spring 2025                        10                   0   \n",
      "Midday         Fall 2021                          21                   0   \n",
      "               Spring 2022                        17                   0   \n",
      "               Fall 2022                          17                   0   \n",
      "               Spring 2023                        17                   0   \n",
      "               Fall 2023                          22                   0   \n",
      "               Spring 2024                        24                   0   \n",
      "               Fall 2024                          36                   0   \n",
      "               Spring 2025                        39                   0   \n",
      "Afternoon      Fall 2021                          16                   0   \n",
      "               Spring 2022                        11                   0   \n",
      "               Fall 2022                          11                   0   \n",
      "               Spring 2023                        17                   0   \n",
      "               Fall 2023                          14                   0   \n",
      "               Spring 2024                        16                   0   \n",
      "               Fall 2024                          19                   0   \n",
      "               Spring 2025                        21                   0   \n",
      "Late Afternoon Fall 2021                           2                   0   \n",
      "               Spring 2022                         1                   0   \n",
      "               Fall 2022                           1                   0   \n",
      "               Spring 2023                         1                   0   \n",
      "               Fall 2023                           3                   0   \n",
      "               Fall 2024                           1                   0   \n",
      "NoTime         Fall 2021                          84                  32   \n",
      "               Spring 2022                        77                  27   \n",
      "               Fall 2022                          75                  30   \n",
      "               Spring 2023                        73                  34   \n",
      "               Fall 2023                          78                  38   \n",
      "               Spring 2024                        76                  43   \n",
      "               Fall 2024                          69                  42   \n",
      "               Spring 2025                        74                  41   \n",
      "\n",
      "Session                     Seven Week - Second  \n",
      "Time Slot      Term                              \n",
      "Morning        Fall 2021                      0  \n",
      "               Spring 2022                    0  \n",
      "               Fall 2022                      0  \n",
      "               Spring 2023                    0  \n",
      "               Fall 2023                      0  \n",
      "               Spring 2024                    0  \n",
      "               Fall 2024                      0  \n",
      "               Spring 2025                    0  \n",
      "Midday         Fall 2021                      0  \n",
      "               Spring 2022                    0  \n",
      "               Fall 2022                      0  \n",
      "               Spring 2023                    0  \n",
      "               Fall 2023                      0  \n",
      "               Spring 2024                    0  \n",
      "               Fall 2024                      0  \n",
      "               Spring 2025                    0  \n",
      "Afternoon      Fall 2021                      0  \n",
      "               Spring 2022                    0  \n",
      "               Fall 2022                      0  \n",
      "               Spring 2023                    0  \n",
      "               Fall 2023                      0  \n",
      "               Spring 2024                    0  \n",
      "               Fall 2024                      0  \n",
      "               Spring 2025                    0  \n",
      "Late Afternoon Fall 2021                      0  \n",
      "               Spring 2022                    0  \n",
      "               Fall 2022                      0  \n",
      "               Spring 2023                    0  \n",
      "               Fall 2023                      0  \n",
      "               Fall 2024                      0  \n",
      "NoTime         Fall 2021                     26  \n",
      "               Spring 2022                   38  \n",
      "               Fall 2022                     33  \n",
      "               Spring 2023                   38  \n",
      "               Fall 2023                     37  \n",
      "               Spring 2024                   43  \n",
      "               Fall 2024                     38  \n",
      "               Spring 2025                   45  \n"
     ]
    }
   ],
   "source": [
    "# .groupby([\"Term\", \"Time Slot\", \"Session\"])\n",
    "time_session_term = df_all_times.groupby([\"Term\", \"Time Slot\", \"Session\"]).size().unstack(fill_value=0)\n",
    "\n",
    "# Reorder: \n",
    "time_session_term = time_session_term.reorder_levels([\"Time Slot\", \"Term\"])     # Reorder: Time Slot first, then Term\n",
    "time_session_term = time_session_term.reindex(ordered_time, level=\"Time Slot\")  # Reorder: time slots by ordered_time order\n",
    "# Reorder semesters within each Time Slot (multi-index) using semester_order_func on Term\n",
    "time_session_term = time_session_term.loc[sorted(time_session_term.index,\n",
    "                                                 key=lambda x: (ordered_time.index(x[0]), semester_order_func(x[1])))]\n",
    "\n",
    "print(\"Time Slot Totals by 15/7 Week & Semester\")\n",
    "print(time_session_term)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of Day: By Days Scheduled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Slot Totals by Days Scheduled\n",
      "Meeting Days       -   F   M  MW  R  T   TR  W\n",
      "Time Slot                                     \n",
      "Morning            0   6  21   3  0  0   11  0\n",
      "Midday             0  26   7  43  1  0  111  5\n",
      "Afternoon          0   2   6  30  1  1   78  7\n",
      "Late Afternoon     0   0   0   3  1  0    5  0\n",
      "NoTime          1191   0   0   0  0  0    0  0\n"
     ]
    }
   ],
   "source": [
    "# Time Slots by Days\n",
    "time_slot_days = df_all_times.groupby([\"Time Slot\", \"Meeting Days\"]).size().unstack(fill_value=0)\n",
    "time_slot_days = time_slot_days.reindex(ordered_time)\n",
    "\n",
    "print(\"Time Slot Totals by Days Scheduled\")\n",
    "print(time_slot_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of Day by Days Scheduled & Semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of Day by Days & Semester\n",
      "Time Slot                 Morning  Midday  Afternoon  Late Afternoon  NoTime\n",
      "Term        Meeting Days                                                    \n",
      "Fall 2021   -                   0       0          0               0     142\n",
      "            F                   0       1          0               0       0\n",
      "            MW                  0       7          5               0       0\n",
      "            R                   0       1          1               1       0\n",
      "            TR                  7      12          8               1       0\n",
      "            W                   0       0          2               0       0\n",
      "Spring 2022 -                   0       0          0               0     142\n",
      "            F                   0       2          0               0       0\n",
      "            M                   3       1          1               0       0\n",
      "            MW                  0       3          2               0       0\n",
      "            TR                  0      11          8               1       0\n",
      "Fall 2022   -                   0       0          0               0     138\n",
      "            F                   1       2          0               0       0\n",
      "            M                   2       0          1               0       0\n",
      "            MW                  0       1          1               1       0\n",
      "            TR                  0      14          9               0       0\n",
      "Spring 2023 -                   0       0          0               0     145\n",
      "            F                   0       2          0               0       0\n",
      "            M                   3       1          1               0       0\n",
      "            MW                  0       3          3               1       0\n",
      "            TR                  0      11         12               0       0\n",
      "            W                   0       0          1               0       0\n",
      "Fall 2023   -                   0       0          0               0     153\n",
      "            F                   0       2          0               0       0\n",
      "            M                   3       1          0               0       0\n",
      "            MW                  0       5          4               1       0\n",
      "            TR                  0      14          9               2       0\n",
      "            W                   0       0          1               0       0\n",
      "Spring 2024 -                   0       0          0               0     162\n",
      "            F                   1       2          0               0       0\n",
      "            M                   3       1          1               0       0\n",
      "            MW                  0       7          3               0       0\n",
      "            TR                  0      14         11               0       0\n",
      "            W                   0       0          1               0       0\n",
      "Fall 2024   -                   0       0          0               0     149\n",
      "            F                   2       8          1               0       0\n",
      "            M                   3       1          1               0       0\n",
      "            MW                  1       9          7               0       0\n",
      "            TR                  2      15         10               1       0\n",
      "            W                   0       3          0               0       0\n",
      "Spring 2025 -                   0       0          0               0     160\n",
      "            F                   2       7          1               0       0\n",
      "            M                   4       2          1               0       0\n",
      "            MW                  2       8          5               0       0\n",
      "            T                   0       0          1               0       0\n",
      "            TR                  2      20         11               0       0\n",
      "            W                   0       2          2               0       0\n"
     ]
    }
   ],
   "source": [
    "# Group by Term (semester), Meeting Days, and Time Slot\n",
    "time_day_semester = df_all_times.groupby([\"Term\", \"Meeting Days\", \"Time Slot\"]).size().unstack(fill_value=0)\n",
    "# Reorder Time Slots by ordered_time\n",
    "time_day_semester = time_day_semester[ordered_time] if set(ordered_time).issubset(time_day_semester.columns) else time_day_semester\n",
    "# Reorder Semesters with func semester_order_func (multi-index)\n",
    "time_day_semester = time_day_semester.loc[sorted(time_day_semester.index, key=lambda x: semester_order_func(x[0]))]\n",
    "\n",
    "print(\"Time of Day by Days & Semester\")\n",
    "print(time_day_semester)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time of Day by Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of Day by Component\n",
      "Component       Colloquium  Discussion  Lecture\n",
      "Time Slot                                      \n",
      "Morning                  0          26       15\n",
      "Midday                   0          39      154\n",
      "Afternoon                7           7      111\n",
      "Late Afternoon           0           1        8\n",
      "NoTime                   0         109     1082\n",
      "\n",
      "Time of Day by Component & Semester\n",
      "Component                   Colloquium  Discussion  Lecture\n",
      "Time Slot      Term                                        \n",
      "Morning        Fall 2021             0           0        7\n",
      "               Spring 2022           0           3        0\n",
      "               Fall 2022             0           3        0\n",
      "               Spring 2023           0           3        0\n",
      "               Fall 2023             0           3        0\n",
      "               Spring 2024           0           3        1\n",
      "               Fall 2024             0           5        3\n",
      "               Spring 2025           0           6        4\n",
      "Midday         Fall 2021             0           2       19\n",
      "               Spring 2022           0           3       14\n",
      "               Fall 2022             0           2       15\n",
      "               Spring 2023           0           3       14\n",
      "               Fall 2023             0           3       19\n",
      "               Spring 2024           0           3       21\n",
      "               Fall 2024             0          12       24\n",
      "               Spring 2025           0          11       28\n",
      "Afternoon      Fall 2021             1           3       12\n",
      "               Spring 2022           1           0       10\n",
      "               Fall 2022             0           1       10\n",
      "               Spring 2023           2           0       15\n",
      "               Fall 2023             0           0       14\n",
      "               Spring 2024           1           0       15\n",
      "               Fall 2024             1           1       17\n",
      "               Spring 2025           1           2       18\n",
      "Late Afternoon Fall 2021             0           1        1\n",
      "               Spring 2022           0           0        1\n",
      "               Fall 2022             0           0        1\n",
      "               Spring 2023           0           0        1\n",
      "               Fall 2023             0           0        3\n",
      "               Fall 2024             0           0        1\n",
      "NoTime         Fall 2021             0          21      121\n",
      "               Spring 2022           0          15      127\n",
      "               Fall 2022             0          14      124\n",
      "               Spring 2023           0          15      130\n",
      "               Fall 2023             0          15      138\n",
      "               Spring 2024           0          15      147\n",
      "               Fall 2024             0           8      141\n",
      "               Spring 2025           0           6      154\n"
     ]
    }
   ],
   "source": [
    "# Time of Day by Component - Totals\n",
    "tod_component = df_all_times.groupby([\"Time Slot\", \"Component\"]).size().unstack(fill_value=0)\n",
    "tod_component = tod_component.reindex(ordered_time)\n",
    "\n",
    "print(\"Time of Day by Component\")\n",
    "print(tod_component)\n",
    "\n",
    "# Time of Day by Component & Semester\n",
    "tod_component_semester = df_all_times.groupby([\"Term\", \"Time Slot\", \"Component\"]).size().unstack(fill_value=0)\n",
    "# Reorder: 1) print Time Slot first, 2) Time Slot by ordered_time, 3) Term by semester_order_func\n",
    "tod_component_semester = tod_component_semester.reorder_levels([\"Time Slot\", \"Term\"]).sort_index(level=\"Time Slot\")\n",
    "tod_component_semester = tod_component_semester.reindex(ordered_time, level=\"Time Slot\")\n",
    "tod_component_semester = tod_component_semester.loc[sorted(tod_component_semester.index,\n",
    "                                                           key=lambda x: (ordered_time.index(x[0]), semester_order_func(x[1])))]\n",
    "\n",
    "print(\"\\nTime of Day by Component & Semester\")\n",
    "print(tod_component_semester)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Course Bottleneck Index (CBI) KDD </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Begin with Defining Terms: DR, OFS, IAS, PCS </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Demand Ratio (DR)</h2>\n",
    "DR = enrollment / capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleanse for DR, group Co-Convened Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_DR_all had 1559 rows before consolidating the co-convened classes\n",
      "\n",
      "df_DR_all has 1047 rows after consolidating the co-convened classes\n"
     ]
    }
   ],
   "source": [
    "df_DR_all = df_all.copy()\n",
    "\n",
    "# Co-Convened? no: df_n_coconvened, yes: df_y_coconvened\n",
    "df_n_coconvened = df_DR_all[df_DR_all[\"Combined Section\"] == \"-\"] # Whether or not value = \"-\"\n",
    "df_y_coconvened = df_DR_all[df_DR_all[\"Combined Section\"] != \"-\"]\n",
    "\n",
    "# Co-Convened Yes Modifications -->\n",
    "# Feed to Aggregate Dictionary: 1) grouping columns; 2) sum columns; 3) all remaining columns, keep \"first\" value\n",
    "cc_group_cols = [\"Term\", \"Combined Section\"]           # same \"term\" & \"combined section\" -> yes co-convened\n",
    "cc_sum_cols = [\"Total Enroll\", \"Enrollment Capacity\"]  # sum Enroll & Capacity if co-convened\n",
    "cc_first_cols = [col for col in df_y_coconvened.columns if col not in cc_group_cols + cc_sum_cols] # all other cols, keep first value\n",
    "\n",
    "# Build the aggregate dictionary for Co-Convened Yes\n",
    "cc_agg_dict = {col: \"sum\" for col in cc_sum_cols}\n",
    "cc_agg_dict.update({col: \"first\" for col in cc_first_cols})\n",
    "\n",
    "# Co-Convened Yes: Group and aggregate\n",
    "df_y_coconvened = df_y_coconvened.groupby(cc_group_cols, as_index=False).agg(cc_agg_dict)\n",
    "\n",
    "# Concatenate the y/n Co-Convened DFs together\n",
    "df_DR_all = pd.concat([df_n_coconvened, df_y_coconvened], ignore_index=True)\n",
    "\n",
    "print(\"df_DR_all had\",df_all.shape[0], \"rows before consolidating the co-convened classes\")\n",
    "print(\"\\ndf_DR_all has\",df_DR_all.shape[0], \"rows after consolidating the co-convened classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DR: Every Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DR for Every Individual Class\n",
    "df_DR_all[\"DR\"] = (df_DR_all[\"Total Enroll\"] / df_DR_all[\"Enrollment Capacity\"]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalize data cleansing for df_DR_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DR_missing = df_DR_all[df_DR_all[\"DR\"].isna()]\n",
    "# All of them are classes with no enrollments & no capacity\n",
    "\n",
    "# Drop the missing values\n",
    "df_DR_all = df_DR_all.dropna(subset=[\"DR\"])\n",
    "\n",
    "# Drop the 2 (discussion) classes that had Enrollments but didn't have Enrollment Capacity (DR = \"inf\")\n",
    "# Statistic Foundations Info Age & Dealing with Data\n",
    "df_DR_all = df_DR_all[df_DR_all[\"DR\"].astype(str) != \"inf\"]\n",
    "\n",
    "# df_DR_all is ready to go!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DR: Total by Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average DR by Course:\n",
      "               Course Description    DR\n",
      "0       Advanced Game Development  0.30\n",
      "1             Advanced Web Design  0.33\n",
      "2            Algorithms for Games  0.68\n",
      "3   Applied Cyberinfrastruct Conc  0.14\n",
      "4      Applied Data Visualization  0.68\n",
      "..                            ...   ...\n",
      "73          Theories of New Media  0.49\n",
      "74       User Interf+Website Dsgn  0.06\n",
      "75                Virtual Reality  0.48\n",
      "76        Visual Content Creation  0.52\n",
      "77              eSport Industries  0.70\n",
      "\n",
      "[78 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_avg_DR = (df_DR_all.groupby(\"Course Description\", as_index=False)[\"DR\"].mean()).round(2)\n",
    "print(\"Average DR by Course:\")\n",
    "print(df_avg_DR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DR Total - Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR Summary Statistics (Overall):\n",
      "Mean DR: 0.48\n",
      "Median DR: 0.53\n",
      "Standard Deviation: 0.24\n",
      "Min DR: 0.02 — Courses: ['Computational Social Science', 'Data Ethics']\n",
      "Max DR: 0.93 — Courses: ['Intro to Creative Coding']\n",
      "\n",
      "Top 5 Highest DR Courses:\n",
      "                Course Description    DR\n",
      "46        Intro to Creative Coding  0.93\n",
      "22    Digital Crime & Social Media  0.91\n",
      "42             Installation Design  0.87\n",
      "12          Computing and the Arts  0.85\n",
      "11  Computational Thinking & Doing  0.84\n",
      "52  Intro: Human Computer Interact  0.77\n",
      "53     Introduction to Game Design  0.76\n",
      "31       Ethics in a Digital World  0.75\n",
      "67      Social Media and Ourselves  0.75\n",
      "70  Statistic Foundations Info Age  0.72\n",
      "\n",
      "Bottom 5 Lowest DR Courses:\n",
      "               Course Description    DR\n",
      "10   Computational Social Science  0.02\n",
      "14                    Data Ethics  0.02\n",
      "7   Bayesian Modeling & Inference  0.03\n",
      "30  Ethical Issues in Information  0.03\n",
      "64                     STEM Games  0.05\n",
      "8            Business Information  0.06\n",
      "74       User Interf+Website Dsgn  0.06\n",
      "65            Science Information  0.08\n",
      "5                     Applied NLP  0.10\n",
      "36         Government Information  0.13\n"
     ]
    }
   ],
   "source": [
    "# Overall stats\n",
    "dr_mean = round(df_avg_DR[\"DR\"].mean(), 2)\n",
    "dr_median = round(df_avg_DR[\"DR\"].median(), 2)\n",
    "dr_std = round(df_avg_DR[\"DR\"].std(), 2)\n",
    "\n",
    "print(\"DR Summary Statistics (Overall):\")\n",
    "print(f\"Mean DR: {dr_mean}\")\n",
    "print(f\"Median DR: {dr_median}\")\n",
    "print(f\"Standard Deviation: {dr_std}\")\n",
    "\n",
    "\n",
    "# DR min/max and course name\n",
    "dr_min = round(df_avg_DR[\"DR\"].min(), 2)\n",
    "dr_max = round(df_avg_DR[\"DR\"].max(), 2)\n",
    "course_min = df_avg_DR.loc[df_avg_DR[\"DR\"] == dr_min, \"Course Description\"].tolist() #Course name(s) as list\n",
    "course_max = df_avg_DR.loc[df_avg_DR[\"DR\"] == dr_max, \"Course Description\"].tolist()\n",
    "\n",
    "print(f\"Min DR: {dr_min} — Courses: {course_min}\")\n",
    "print(f\"Max DR: {dr_max} — Courses: {course_max}\")\n",
    "\n",
    "# Top 10 highest and lowest DR courses\n",
    "top_dr = df_avg_DR.nlargest(10, \"DR\")\n",
    "bottom_dr = df_avg_DR.nsmallest(10, \"DR\")\n",
    "\n",
    "print(\"\\n10 Highest DR Courses:\")\n",
    "print(top_dr)\n",
    "print(\"\\n10 Lowest DR Courses:\")\n",
    "print(bottom_dr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DR: By Term & Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average DR by Course & Term:\n",
      "            Term             Course Description    DR\n",
      "0      Fall 2021            Advanced Web Design  0.26\n",
      "1      Fall 2021           Algorithms for Games  0.52\n",
      "2      Fall 2021  Applied Cyberinfrastruct Conc  0.22\n",
      "3      Fall 2021     Applied Data Visualization  0.72\n",
      "4      Fall 2021  Bayesian Modeling & Inference  0.09\n",
      "..           ...                            ...   ...\n",
      "460  Spring 2025         The Past and New Media  0.34\n",
      "461  Spring 2025          Theories of New Media  0.32\n",
      "462  Spring 2025                Virtual Reality  0.46\n",
      "463  Spring 2025        Visual Content Creation  0.52\n",
      "464  Spring 2025              eSport Industries  0.50\n",
      "\n",
      "[465 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_term_avg_DR = (df_DR_all.groupby([\"Term\", \"Course Description\"], as_index=False)[\"DR\"].mean()).round(2)\n",
    "\n",
    "# Sort by Term\n",
    "df_term_avg_DR = df_term_avg_DR.set_index([\"Term\", \"Course Description\"])\n",
    "df_term_avg_DR = df_term_avg_DR.loc[sorted(df_term_avg_DR.index, key=lambda x: semester_order_func(x[0]))]\n",
    "df_term_avg_DR = df_term_avg_DR.reset_index()\n",
    "\n",
    "print(\"Average DR by Course & Term:\")\n",
    "print(df_term_avg_DR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DR by Term - Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🗓 DR Summary for Fall 2021\n",
      "Mean DR: 0.59\n",
      "Median DR: 0.61\n",
      "Standard Deviation: 0.28\n",
      "Min DR: 0.03 on Courses: ['Ethical Issues in Information']\n",
      "Max DR: 1.02 on Courses: ['eSport Industries']\n",
      "\n",
      "Fall 2021: 5 Highest DR Courses:\n",
      "          Course Description   DR\n",
      "           eSport Industries 1.02\n",
      " Great Ideas of the Info Age 1.01\n",
      "Digital Crime & Social Media 0.96\n",
      "  Social Media and Ourselves 0.96\n",
      "    Intro to Creative Coding 0.95\n",
      "\n",
      " Fall 2021: 5 Lowest DR Courses:\n",
      "           Course Description   DR\n",
      "Ethical Issues in Information 0.03\n",
      "Bayesian Modeling & Inference 0.09\n",
      "     User Interf+Website Dsgn 0.09\n",
      "       Government Information 0.12\n",
      "               Special Topics 0.15\n",
      "\n",
      "🗓 DR Summary for Fall 2022\n",
      "Mean DR: 0.59\n",
      "Median DR: 0.64\n",
      "Standard Deviation: 0.27\n",
      "Min DR: 0.04 on Courses: ['Ethical Issues in Information', 'Science Information']\n",
      "Max DR: 0.98 on Courses: ['Diversity and Bias in Games', 'eSport Industries']\n",
      "\n",
      "Fall 2022: 5 Highest DR Courses:\n",
      "          Course Description   DR\n",
      " Diversity and Bias in Games 0.98\n",
      "           eSport Industries 0.98\n",
      "Digital Crime & Social Media 0.97\n",
      "         Installation Design 0.96\n",
      "  Applied Data Visualization 0.94\n",
      "\n",
      " Fall 2022: 5 Lowest DR Courses:\n",
      "           Course Description   DR\n",
      "Ethical Issues in Information 0.04\n",
      "          Science Information 0.04\n",
      "           Intro to Info Tech 0.10\n",
      "       Government Information 0.12\n",
      "Data Warehousing in the Cloud 0.13\n",
      "\n",
      "🗓 DR Summary for Fall 2023\n",
      "Mean DR: 0.56\n",
      "Median DR: 0.6\n",
      "Standard Deviation: 0.27\n",
      "Min DR: 0.01 on Courses: ['Ethical Issues in Information']\n",
      "Max DR: 1.0 on Courses: ['Gamification in Society']\n",
      "\n",
      "Fall 2023: 5 Highest DR Courses:\n",
      "            Course Description   DR\n",
      "       Gamification in Society 1.00\n",
      "        Computing and the Arts 0.97\n",
      "Computational Thinking & Doing 0.96\n",
      "Statistic Foundations Info Age 0.95\n",
      "  Digital Crime & Social Media 0.94\n",
      "\n",
      " Fall 2023: 5 Lowest DR Courses:\n",
      "           Course Description   DR\n",
      "Ethical Issues in Information 0.01\n",
      "                  Data Ethics 0.02\n",
      "           Intro to Info Tech 0.05\n",
      "          Science Information 0.05\n",
      "       Government Information 0.12\n",
      "\n",
      "🗓 DR Summary for Fall 2024\n",
      "Mean DR: 0.48\n",
      "Median DR: 0.5\n",
      "Standard Deviation: 0.27\n",
      "Min DR: 0.0 on Courses: ['Bayesian Modeling & Inference', 'Data Ethics']\n",
      "Max DR: 1.14 on Courses: ['Neural Networks']\n",
      "\n",
      "Fall 2024: 5 Highest DR Courses:\n",
      "          Course Description   DR\n",
      "             Neural Networks 1.14\n",
      "  Intro. to Game Development 0.98\n",
      "Digital Crime & Social Media 0.91\n",
      "        Algorithms for Games 0.89\n",
      " Introduction to Game Design 0.86\n",
      "\n",
      " Fall 2024: 5 Lowest DR Courses:\n",
      "           Course Description   DR\n",
      "Bayesian Modeling & Inference 0.00\n",
      "                  Data Ethics 0.00\n",
      "           Intro to Info Tech 0.08\n",
      "Ethical Issues in Information 0.09\n",
      "                  Applied NLP 0.10\n",
      "\n",
      "🗓 DR Summary for Spring 2022\n",
      "Mean DR: 0.6\n",
      "Median DR: 0.62\n",
      "Standard Deviation: 0.26\n",
      "Min DR: 0.03 on Courses: ['User Interf+Website Dsgn']\n",
      "Max DR: 1.0 on Courses: ['Ethics in a Digital World']\n",
      "\n",
      "Spring 2022: 5 Highest DR Courses:\n",
      "          Course Description   DR\n",
      "   Ethics in a Digital World 1.00\n",
      "           eSport Industries 0.97\n",
      "Digital Crime & Social Media 0.95\n",
      "  Applied Data Visualization 0.94\n",
      "            Digital Commerce 0.94\n",
      "\n",
      " Spring 2022: 5 Lowest DR Courses:\n",
      "            Course Description   DR\n",
      "      User Interf+Website Dsgn 0.03\n",
      "           Science Information 0.06\n",
      "Intellectual Property/Copyrigh 0.07\n",
      "            Intro to Info Tech 0.07\n",
      "     Designing an Installation 0.12\n",
      "\n",
      "🗓 DR Summary for Spring 2023\n",
      "Mean DR: 0.54\n",
      "Median DR: 0.49\n",
      "Standard Deviation: 0.25\n",
      "Min DR: 0.0 on Courses: ['Ethical Issues in Information']\n",
      "Max DR: 1.01 on Courses: ['Ethics in a Digital World']\n",
      "\n",
      "Spring 2023: 5 Highest DR Courses:\n",
      "           Course Description   DR\n",
      "    Ethics in a Digital World 1.01\n",
      " Collaborating: Online Commun 0.98\n",
      "       Computing and the Arts 0.96\n",
      "Hacking & Open Source Culture 0.96\n",
      "  Introduction to Game Design 0.94\n",
      "\n",
      " Spring 2023: 5 Lowest DR Courses:\n",
      "           Course Description   DR\n",
      "Ethical Issues in Information 0.00\n",
      " Computational Social Science 0.03\n",
      "          Science Information 0.03\n",
      "           Intro to Info Tech 0.11\n",
      "                  Applied NLP 0.12\n",
      "\n",
      "🗓 DR Summary for Spring 2024\n",
      "Mean DR: 0.49\n",
      "Median DR: 0.46\n",
      "Standard Deviation: 0.25\n",
      "Min DR: 0.0 on Courses: ['Computational Social Science']\n",
      "Max DR: 0.98 on Courses: ['Digital Commerce']\n",
      "\n",
      "Spring 2024: 5 Highest DR Courses:\n",
      "            Course Description   DR\n",
      "              Digital Commerce 0.98\n",
      "    Applied Data Visualization 0.97\n",
      "  Intro Web Design-Development 0.96\n",
      "Computational Thinking & Doing 0.93\n",
      "        Computing and the Arts 0.93\n",
      "\n",
      " Spring 2024: 5 Lowest DR Courses:\n",
      "          Course Description   DR\n",
      "Computational Social Science 0.00\n",
      "                 Data Ethics 0.03\n",
      "                  STEM Games 0.07\n",
      "          Intro to Info Tech 0.11\n",
      "                 Applied NLP 0.12\n",
      "\n",
      "🗓 DR Summary for Spring 2025\n",
      "Mean DR: 0.42\n",
      "Median DR: 0.44\n",
      "Standard Deviation: 0.23\n",
      "Min DR: 0.0 on Courses: ['Bayesian Modeling & Inference']\n",
      "Max DR: 0.98 on Courses: ['Ethics in a Digital World']\n",
      "\n",
      "Spring 2025: 5 Highest DR Courses:\n",
      "          Course Description   DR\n",
      "   Ethics in a Digital World 0.98\n",
      "Digital Crime & Social Media 0.88\n",
      "         Installation Design 0.83\n",
      "            Game Development 0.80\n",
      "      Computing and the Arts 0.78\n",
      "\n",
      " Spring 2025: 5 Lowest DR Courses:\n",
      "           Course Description   DR\n",
      "Bayesian Modeling & Inference 0.00\n",
      "                  Data Ethics 0.01\n",
      "                  Applied NLP 0.03\n",
      "Ethical Issues in Information 0.03\n",
      "                   STEM Games 0.03\n"
     ]
    }
   ],
   "source": [
    "# For Loop for our summary stats (mean, median, std, min/max) and top/bottom 5 courses\n",
    "for df_semester, group in df_term_avg_DR.groupby(\"Term\"):\n",
    "    # Summary stats (mean, median, std)\n",
    "    dr_mean = round(group[\"DR\"].mean(), 2)\n",
    "    dr_median = round(group[\"DR\"].median(), 2)\n",
    "    dr_std = round(group[\"DR\"].std(), 2)\n",
    "    print(f\"\\n🗓 DR Summary for {df_semester}\") # emoji to make it easier to read\n",
    "    print(f\"Mean DR: {dr_mean}\")\n",
    "    print(f\"Median DR: {dr_median}\")\n",
    "    print(f\"Standard Deviation: {dr_std}\")\n",
    "\n",
    "    # Min/Max and course name(s)\n",
    "    dr_min = round(group[\"DR\"].min(), 2)\n",
    "    dr_max = round(group[\"DR\"].max(), 2)\n",
    "    course_min = group.loc[group[\"DR\"] == dr_min, \"Course Description\"].tolist()\n",
    "    course_max = group.loc[group[\"DR\"] == dr_max, \"Course Description\"].tolist()\n",
    "    print(f\"Min DR: {dr_min} on Courses: {course_min}\")\n",
    "    print(f\"Max DR: {dr_max} on Courses: {course_max}\")\n",
    "\n",
    "    #Top/Bottom 5\n",
    "    top_5 = group.nlargest(5, \"DR\")[[\"Course Description\", \"DR\"]]\n",
    "    bottom_5 = group.nsmallest(5, \"DR\")[[\"Course Description\", \"DR\"]]\n",
    "    print(f\"\\n{df_semester}: 5 Highest DR Courses:\")\n",
    "    print(top_5.to_string(index=False))\n",
    "    print(f\"\\n {df_semester}: 5 Lowest DR Courses:\")\n",
    "    print(bottom_5.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Offering Frequency Score (OFS)</h2>\n",
    "Captures how often a course if offered: 1: every semester, 2: once a year, 3: less than once a year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Courses by \"Course Description\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes by Course Description:\n",
      "Course Description\n",
      "Statistic Foundations Info Age    77\n",
      "Digital Storytelling & Culture    74\n",
      "Computational Thinking & Doing    72\n",
      "Social Media and Ourselves        50\n",
      "Dealing with Data                 49\n",
      "                                  ..\n",
      "Foundation of Info & Inference     2\n",
      "Game AI                            2\n",
      "Designing an Installation          2\n",
      "Natural Language Processing        1\n",
      "Visual Content Creation            1\n",
      "Length: 81, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Total Courses by \"Course Description\"\n",
    "course_totals = df_all.groupby(\"Course Description\").size().sort_values(ascending=False)\n",
    "print(\"Total Classes by Course Description:\")\n",
    "print(course_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Courses by Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes by Semester:\n",
      "Term             Course Description  Fall 2021  Spring 2022  Fall 2022  \\\n",
      "0         Advanced Game Development          0            1          1   \n",
      "1               Advanced Web Design          2            2          0   \n",
      "2              Algorithms for Games          1            1          1   \n",
      "3     Applied Cyberinfrastruct Conc          6            0          0   \n",
      "4        Applied Data Visualization          2            2          2   \n",
      "..                              ...        ...          ...        ...   \n",
      "76            Theories of New Media          8            6          4   \n",
      "77         User Interf+Website Dsgn          2            2          0   \n",
      "78                  Virtual Reality          1            1          1   \n",
      "79          Visual Content Creation          0            0          0   \n",
      "80                eSport Industries          2            4          2   \n",
      "\n",
      "Term  Spring 2023  Fall 2023  Spring 2024  Fall 2024  Spring 2025  \n",
      "0               1          1            2          2            2  \n",
      "1               0          0            0          0            1  \n",
      "2               1          1            0          1            0  \n",
      "3               0          0            0          0            6  \n",
      "4               2          2            2          4            4  \n",
      "..            ...        ...          ...        ...          ...  \n",
      "76              4          4            5          4            6  \n",
      "77              0          0            0          0            0  \n",
      "78              2          2            2          2            4  \n",
      "79              0          0            0          0            1  \n",
      "80              4          4            4          4            4  \n",
      "\n",
      "[81 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "course_total_by_semester = df_all.groupby([\"Course Description\", \"Term\"]).size().unstack(fill_value=0)\n",
    "course_total_by_semester = course_total_by_semester[sorted(course_total_by_semester.columns, key=semester_order_func)]\n",
    "course_total_by_semester = course_total_by_semester.reset_index()   #Include Course Description as a column, was being dropped\n",
    "\n",
    "print(\"Total Classes by Semester:\")\n",
    "print(course_total_by_semester)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Get OFS Score (get_OFS)\n",
    "\n",
    "1: Every Semester. 2: Once a year. 3: Less than once a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OFS = course_total_by_semester.copy()\n",
    "\n",
    "# Specify Col Names because was having issues with indexing \n",
    "semester_cols = [\"Fall 2021\", \"Spring 2022\", \"Fall 2022\", \"Spring 2023\",\n",
    "                 \"Fall 2023\", \"Spring 2024\", \"Fall 2024\", \"Spring 2025\"]\n",
    "\n",
    "# Add \"Term Count\" Column: count of Non-Zero values in semester_cols to double check our 1/2/3s\n",
    "df_OFS[\"TermCount\"] = df_OFS[semester_cols].ne(0).sum(axis=1)\n",
    "\n",
    "# OFS Function: Assign 1, 2, and 3\n",
    "def get_OFS(row):\n",
    "    semester_vals = row[semester_cols].values  # only the 8 columns\n",
    "    nonzero_count = (semester_vals != 0).sum()\n",
    "\n",
    "    if nonzero_count >= 7:    # 1, Every semester: at least 7 of the last 8 semesters\n",
    "        return 1\n",
    "    elif nonzero_count <= 3:  # 3, Less than once a year: if offered 3 semesters or fewer\n",
    "        return 3\n",
    "    else:                     # 2, Every other semester: if offered 4-6 semesters\n",
    "        return 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate & Print OFS Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Descriptions & Their Offering Frequency Score (OFS):\n",
      "Term             Course Description  TermCount  OFS\n",
      "0         Advanced Game Development          7    1\n",
      "1               Advanced Web Design          3    3\n",
      "2              Algorithms for Games          6    2\n",
      "3     Applied Cyberinfrastruct Conc          2    3\n",
      "4        Applied Data Visualization          8    1\n",
      "..                              ...        ...  ...\n",
      "76            Theories of New Media          8    1\n",
      "77         User Interf+Website Dsgn          2    3\n",
      "78                  Virtual Reality          8    1\n",
      "79          Visual Content Creation          1    3\n",
      "80                eSport Industries          8    1\n",
      "\n",
      "[81 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Run our get_OFS to get 1/2/3 OFS scores\n",
    "df_OFS[\"OFS\"] = df_OFS.apply(get_OFS, axis=1)\n",
    "\n",
    "# Smaller DF for printing: keep just Course Description\", \"TermCount\", & \"OFS\"\n",
    "df_OFS_small = df_OFS[[\"Course Description\", \"TermCount\", \"OFS\"]]\n",
    "\n",
    "print(\"Course Descriptions & Their Offering Frequency Score (OFS):\")\n",
    "print(df_OFS_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OFS Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offering Frequency Score (OFS) Summary Stats:\n",
      "\n",
      "OFS Score 1: 46 total courses with an Average Term Count of 7.91\n",
      "OFS Score 2: 14 total courses with an Average Term Count of 5.0\n",
      "OFS Score 3: 21 total courses with an Average Term Count of 2.29\n"
     ]
    }
   ],
   "source": [
    "# Set up DFs for OFSxCounts and OFSxAverage-TermCount\n",
    "ofs_counts = df_OFS_small[\"OFS\"].value_counts().sort_index()                    # counting the OFS scores\n",
    "ofs_termcount_avg = df_OFS_small.groupby(\"OFS\")[\"TermCount\"].mean().round(2)    # group by OFS to get average Term Count\n",
    "\n",
    "print(\"Offering Frequency Score (OFS) Summary Stats:\\n\")\n",
    "for ofs_score in sorted(ofs_counts.index):\n",
    "    count = ofs_counts[ofs_score]\n",
    "    avg_terms = ofs_termcount_avg[ofs_score]\n",
    "    print(f\"OFS Score {ofs_score}: {count} total courses with an Average Term Count of {avg_terms}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Prerequisite Complexity Score (PCS) </h2>\n",
    "0: No Prerequisites. 1: Yes Prerequisites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Instructor Availability Score (IAS) & Prerequisite Complexity Score (PCS) raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IAS_raw = pd.read_excel(os.path.join(base_path, \"2022_2025_Faculty Load Analysis - CLEANED.xlsx\"))\n",
    "df_PCS_raw = pd.read_excel(os.path.join(base_path, \"Course List w. Pre-Reqs.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean PCS dataframe to just be UGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undergrad PCS rows: 181\n"
     ]
    }
   ],
   "source": [
    "# Make a copy to avoid modifying the original\n",
    "df_PCS_ugrad = df_PCS_raw.copy()\n",
    "\n",
    "# Temporary Column \"Catalog_First_Digit\":\n",
    "# Extract first digit from Catalog # and convert to float (<5 is undergrad)\n",
    "df_PCS_ugrad[\"Catalog_First_Digit\"] = df_PCS_ugrad[\"Catalog #\"].astype(str).str[0].str.extract(r\"(\\d)\").astype(float)\n",
    "df_PCS_ugrad = df_PCS_ugrad[df_PCS_ugrad[\"Catalog_First_Digit\"] < 5].copy()\n",
    "df_PCS_ugrad.drop(columns=\"Catalog_First_Digit\", inplace=True) # Remove temporary column\n",
    "\n",
    "print(f\"Undergrad PCS rows: {df_PCS_ugrad.shape[0]}\")\n",
    "\n",
    "# There are more UGrad class options loaded here than we did in the original cleaned dataset\n",
    "# My df_all was more filtered than this df_PCS copy --> will just keep the values that match in my df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCS: Fill my DF (df_PCS_all, from df_all) with PreReqs from our raw data df_PCS_ugrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New DF df_PCS_all from df_all to do our PCS analysis\n",
    "df_PCS_all = df_all.copy()\n",
    "\n",
    "# Create empty PCS column to store y/n from df_PCS_ugrad\n",
    "df_PCS_all[\"PCS\"] = None  # or np.nan if you want\n",
    "\n",
    "# Create map for matching df_PCS_ugrad's Course Descriptions (raw data) into our working df_PCS_all\n",
    "PCS_map = (df_PCS_ugrad[[\"Course Description\", \"Requirements\"]]\n",
    "    .drop_duplicates(\"Course Description\")              # keep first match Course Description\n",
    "    .set_index(\"Course Description\")[\"Requirements\"])   # set index to Course Description, get values from Requirements column\n",
    "\n",
    "# Fill PCS column with matching Requirements\n",
    "df_PCS_all[\"PCS\"] = df_PCS_all[\"Course Description\"].map(PCS_map)\n",
    "\n",
    "# Convert Y/- to 1 (yes) & 0 (no)\n",
    "df_PCS_all[\"PCS\"] = (df_PCS_all[\"PCS\"] == \"Y\").astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCS Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Course Description  PCS\n",
      "0       Advanced Game Development    1\n",
      "1             Advanced Web Design    1\n",
      "2            Algorithms for Games    1\n",
      "3   Applied Cyberinfrastruct Conc    1\n",
      "4      Applied Data Visualization    1\n",
      "..                            ...  ...\n",
      "76          Theories of New Media    0\n",
      "77       User Interf+Website Dsgn    0\n",
      "78                Virtual Reality    1\n",
      "79        Visual Content Creation    0\n",
      "80              eSport Industries    0\n",
      "\n",
      "[81 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_PCS_scores = df_PCS_all.groupby(\"Course Description\", as_index=False)[\"PCS\"].max()\n",
    "\n",
    "print(df_PCS_scores[[\"Course Description\", \"PCS\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which classes dropped from DR (78 vs 81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped courses:\n",
      "{'Natural Language Processing', 'Simulation and Problem Solving', 'Special Topics in LIS'}\n"
     ]
    }
   ],
   "source": [
    "dropped_courses = set(df_PCS_scores[\"Course Description\"]) - set(df_avg_DR[\"Course Description\"])\n",
    "print(\"Courses without a DR:\")\n",
    "print(dropped_courses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCS Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prerequisite Complexity Score (PCS) Summary Stats:\n",
      "PCS Score 0: 50\n",
      "PCS Score 1: 31\n"
     ]
    }
   ],
   "source": [
    "# Set up DF for PCSxCounts \n",
    "pcs_counts = df_PCS_scores[\"PCS\"].value_counts().sort_index()\n",
    "\n",
    "print(\"Prerequisite Complexity Score (PCS) Summary Stats:\")\n",
    "for pcs_score in sorted(pcs_counts.index):\n",
    "    count = pcs_counts[pcs_score]\n",
    "    print(f\"PCS Score {pcs_score}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Instructor Availability Score (IAS)</h2>\n",
    "IAS = 1/[number of instructors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleanse df_IAS_raw a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IAS_raw_ugrad = df_IAS_raw.copy()\n",
    "\n",
    "# Keep specific sessions\n",
    "df_IAS_raw_ugrad = df_IAS_raw_ugrad[df_IAS_raw_ugrad[\"Session\"].isin([\"Regular Academic Session\", \n",
    "    \"Seven Week - First\", \"Seven Week - Second\"])]\n",
    "\n",
    "# Keep specific campuses\n",
    "df_IAS_raw_ugrad = df_IAS_raw_ugrad[df_IAS_raw_ugrad[\"Class Campus\"].isin([\"University of Arizona - Main\", \"Arizona Online\"])]\n",
    "\n",
    "# Filter for ugrad: first digit <5 is ugrad\n",
    "df_IAS_raw_ugrad[\"Catalog_First_Digit\"] = df_IAS_raw_ugrad[\"Catalog Number\"].astype(str).str[0].str.extract(r\"(\\d)\").astype(float)\n",
    "df_IAS_raw_ugrad = df_IAS_raw_ugrad[df_IAS_raw_ugrad[\"Catalog_First_Digit\"] < 5].copy()\n",
    "df_IAS_raw_ugrad.drop(columns=\"Catalog_First_Digit\", inplace=True) # Remove temporary column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the df_IAS_raw_ugrad with what I'll use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IAS_all = df_all.copy()\n",
    "\n",
    "# If these 4 cols match, we can assume it's the same class in both DFs\n",
    "merge_cols = [\"Term\", \"Session\", \"Subject Code\", \"Catalog Number\"]\n",
    "\n",
    "# Merge Keys: Create Unique Identifier from the 4 columns above\n",
    "df_IAS_all[\"merge_key\"] = df_IAS_all[merge_cols].astype(str).agg(\"_\".join, axis=1)\n",
    "df_IAS_raw_ugrad[\"merge_key\"] = df_IAS_raw_ugrad[merge_cols].astype(str).agg(\"_\".join, axis=1)\n",
    "\n",
    "pseudo_lookup = (df_IAS_raw_ugrad[[\"merge_key\", \"Psuedonymn\"]]\n",
    "    .drop_duplicates(\"merge_key\")  # keep first match\n",
    "    .set_index(\"merge_key\")[\"Psuedonymn\"])\n",
    "load_lookup = (df_IAS_raw_ugrad[[\"merge_key\", \"Instructor Load Factor\"]]\n",
    "    .drop_duplicates(\"merge_key\")\n",
    "    .set_index(\"merge_key\")[\"Instructor Load Factor\"])\n",
    "\n",
    "role_lookup = (df_IAS_raw_ugrad[[\"merge_key\", \"Instructor Role\"]]\n",
    "    .drop_duplicates(\"merge_key\")\n",
    "    .set_index(\"merge_key\")[\"Instructor Role\"])\n",
    "\n",
    "df_IAS_all[\"Instructor Load Factor\"] = df_IAS_all[\"merge_key\"].map(load_lookup)\n",
    "df_IAS_all[\"Instructor Role\"] = df_IAS_all[\"merge_key\"].map(role_lookup)\n",
    "\n",
    "\n",
    "df_IAS_all[\"Pseudonym\"] = df_IAS_all[\"merge_key\"].map(pseudo_lookup)\n",
    "df_IAS_all[\"Instructor Load Factor\"] = df_IAS_all[\"merge_key\"].map(load_lookup)\n",
    "df_IAS_all[\"Instructor Role\"] = df_IAS_all[\"merge_key\"].map(role_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore missing data\n",
    "?? need Course ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IAS_missing = df_IAS_all.copy()\n",
    "\n",
    "df_IAS_missing = df_IAS_all[df_IAS_all[[\"Instructor Load Factor\", \"Instructor Role\", \"Pseudonym\"]].isna().any(axis=1)].copy()\n",
    "\n",
    "# 204 rows / 13% of our data is missing \"Instructor Load Factor\", \"Instructor Role\", \"Pseudonym\"\n",
    "# Error Source was not my data cleansing - same 204 count either way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "?? temporarily removing missing values to continue with code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IAS_all = df_IAS_all.dropna(subset=[\"Instructor Load Factor\", \"Instructor Role\", \"Pseudonym\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IAS by Total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IAS_tot = df_IAS_all.copy()\n",
    "\n",
    "# Group by Course Description; count unique Pseudonyms\n",
    "instructor_counts = df_IAS_tot.groupby(\"Course Description\")[\"Pseudonym\"].nunique()\n",
    "\n",
    "# Create new DataFrame with Course Description, Instructor Count, and IAS\n",
    "df_IAS_tot = instructor_counts.reset_index()\n",
    "df_IAS_tot.rename(columns={\"Pseudonym\": \"Instructor Count\"}, inplace=True)\n",
    "df_IAS_tot[\"IAS\"] = (1 / df_IAS_tot[\"Instructor Count\"]).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IAS_tot = df_IAS_all.copy()\n",
    "\n",
    "# Empty column for Instructor Count\n",
    "df_IAS_tot[\"Instructor Count\"] = None\n",
    "\n",
    "# Group by Course Description; count unique Pseudonyms\n",
    "instructor_counts = df_IAS_tot.groupby(\"Course Description\")[\"Pseudonym\"].nunique()\n",
    "\n",
    "# Fill Instructor Count with counts of unique Pseudonyms by course\n",
    "df_IAS_tot[\"Instructor Count\"] = df_IAS_tot[\"Course Description\"].map(instructor_counts)\n",
    "\n",
    "# Reorganize: Drop unecessary columns, consolidate to unique Course Descriptions\n",
    "df_IAS_tot.drop(columns=[\"merge_key\", \"Instructor Load Factor\", \"Instructor Role\", \"Pseudonym\"], inplace=True) # drop these - no longer necessary\n",
    "df_IAS_tot = df_IAS_tot.groupby(\"Course Description\", as_index=False).first()\n",
    "\n",
    "# Add IAS column & scores; IAS = 1 / Instructor Count\n",
    "df_IAS_tot[\"IAS\"] = (1 / df_IAS_tot[\"Instructor Count\"]).round(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Descriptions & Their Instructor Availability Score (IAS):\n",
      "               Course Description  Instructor Count   IAS\n",
      "0       Advanced Game Development                 2  0.50\n",
      "1             Advanced Web Design                 2  0.50\n",
      "2            Algorithms for Games                 1  1.00\n",
      "3   Applied Cyberinfrastruct Conc                 1  1.00\n",
      "4      Applied Data Visualization                 4  0.25\n",
      "..                            ...               ...   ...\n",
      "75          Theories of New Media                 3  0.33\n",
      "76       User Interf+Website Dsgn                 1  1.00\n",
      "77                Virtual Reality                 2  0.50\n",
      "78        Visual Content Creation                 1  1.00\n",
      "79              eSport Industries                 1  1.00\n",
      "\n",
      "[80 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Smaller DF for printing\n",
    "df_IAS_tot_small = df_IAS_tot[[\"Course Description\", \"Instructor Count\", \"IAS\"]]\n",
    "\n",
    "print(\"Course Descriptions & Their Instructor Availability Score (IAS):\")\n",
    "print(df_IAS_tot_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IAS Totals - Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructor Availability Score (IAS) Counts by Score:\n",
      "PCS Score 0.14: 1\n",
      "PCS Score 0.25: 6\n",
      "PCS Score 0.33: 7\n",
      "PCS Score 0.5: 28\n",
      "PCS Score 1.0: 38\n",
      "\n",
      "Instructor Availability Score (IAS) Summary Stats (Overall):\n",
      "Mean IAS: 0.7\n",
      "Median IAS: 0.5\n",
      "Standard Deviation: 0.3\n",
      "Min IAS: 0.14 — Courses: ['Intro to Machine Learning']\n",
      "Max IAS: 1.0 — Courses: ['Algorithms for Games', 'Applied Cyberinfrastruct Conc', 'Applied NLP', 'Bayesian Modeling & Inference', 'Collaborating: Online Commun', 'Computational Social Science', 'Data Ethics', 'Database Dev and Mgmt', 'Designing an Installation', 'Dig Games and Society', 'Digital Commerce', 'Digital Crime & Social Media', 'Disruptive Technologies', 'Esports Casting', 'Foundation of Info & Inference', 'Game AI', 'Game Development', 'Gamification in Society', 'Government Information', 'Great Ideas of the Info Age', 'Hacking & Open Source Culture', 'Information Security', 'Instructional Technologies', 'Intro to Data Science', 'Intro to Info Tech', 'Monetizing Independent Gaming', 'Narrative in Digital Games', 'Natural Language Processing', 'Online Searching', 'Prog for Informatics Apps', 'STEM Games', 'Science Information', 'Special Topics', 'Special Topics in LIS', 'The Past and New Media', 'User Interf+Website Dsgn', 'Visual Content Creation', 'eSport Industries']\n",
      "\n",
      "5 Highest IAS Courses:\n",
      "              Course Description  Instructor Count  IAS\n",
      "2           Algorithms for Games                 1  1.0\n",
      "3  Applied Cyberinfrastruct Conc                 1  1.0\n",
      "5                    Applied NLP                 1  1.0\n",
      "7  Bayesian Modeling & Inference                 1  1.0\n",
      "9   Collaborating: Online Commun                 1  1.0\n",
      "\n",
      "5 Lowest IAS Courses:\n",
      "                Course Description  Instructor Count   IAS\n",
      "50       Intro to Machine Learning                 7  0.14\n",
      "4       Applied Data Visualization                 4  0.25\n",
      "23                Digital Dilemmas                 4  0.25\n",
      "26  Digital Storytelling & Culture                 4  0.25\n",
      "30   Ethical Issues in Information                 4  0.25\n"
     ]
    }
   ],
   "source": [
    "# Counts by IAS Score\n",
    "ias_counts = df_IAS_tot_small[\"IAS\"].value_counts().sort_index()\n",
    "\n",
    "print(\"Instructor Availability Score (IAS) Counts by Score:\")\n",
    "for ias_score in sorted(ias_counts.index):\n",
    "    count = ias_counts[ias_score]\n",
    "    print(f\"PCS Score {ias_score}: {count}\")\n",
    "\n",
    "# Overall stats (same code as DR Total)\n",
    "ias_mean = round(df_IAS_tot_small[\"IAS\"].mean(), 2)\n",
    "ias_median = round(df_IAS_tot_small[\"IAS\"].median(), 2)\n",
    "ias_std = round(df_IAS_tot_small[\"IAS\"].std(), 2)\n",
    "print(\"\\nInstructor Availability Score (IAS) Summary Stats (Overall):\")\n",
    "print(f\"Mean IAS: {ias_mean}\")\n",
    "print(f\"Median IAS: {ias_median}\")\n",
    "print(f\"Standard Deviation: {ias_std}\")\n",
    "\n",
    "# IAS min/max and course name\n",
    "ias_min = round(df_IAS_tot_small[\"IAS\"].min(), 2)\n",
    "ias_max = round(df_IAS_tot_small[\"IAS\"].max(), 2)\n",
    "ias_course_min = df_IAS_tot_small.loc[df_IAS_tot_small[\"IAS\"] == ias_min, \"Course Description\"].tolist() #Course name(s) as list\n",
    "ias_course_max = df_IAS_tot_small.loc[df_IAS_tot_small[\"IAS\"] == ias_max, \"Course Description\"].tolist()\n",
    "\n",
    "print(f\"Min IAS: {ias_min} — Courses: {ias_course_min}\")\n",
    "print(f\"Max IAS: {ias_max} — Courses: {ias_course_max}\")\n",
    "\n",
    "# Top 5 highest and lowest IAS courses\n",
    "top_ias = df_IAS_tot_small.nlargest(5, \"IAS\")\n",
    "bottom_ias = df_IAS_tot_small.nsmallest(5, \"IAS\")\n",
    "\n",
    "print(\"\\n5 Highest IAS Courses:\")\n",
    "print(top_ias)\n",
    "print(\"\\n5 Lowest IAS Courses:\")\n",
    "print(bottom_ias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IAS by Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IAS_term = df_IAS_all.copy()\n",
    "\n",
    "# Empty column for Instructor Count\n",
    "df_IAS_term[\"Instructor Count\"] = None\n",
    "\n",
    "# Group by Course Description; count unique Pseudonyms\n",
    "instructor_counts2 = df_IAS_term.groupby([\"Term\", \"Course Description\"])[\"Pseudonym\"].nunique()\n",
    "\n",
    "# Fill Instructor Count with counts of unique Pseudonyms by course\n",
    "df_IAS_term[\"Instructor Count\"] = df_IAS_term.set_index([\"Term\", \"Course Description\"]).index.map(instructor_counts2)\n",
    "\n",
    "# Reorganize: Drop unecessary columns, consolidate to unique Course Descriptions\n",
    "df_IAS_term.drop(columns=[\"merge_key\", \"Instructor Load Factor\", \"Instructor Role\", \"Pseudonym\"], inplace=True) # drop these - no longer necessary\n",
    "df_IAS_term = df_IAS_term.groupby([\"Term\", \"Course Description\"], as_index=False).first()\n",
    "\n",
    "# Add IAS column & scores; IAS = 1 / Instructor Count\n",
    "df_IAS_term[\"IAS\"] = (1 / df_IAS_term[\"Instructor Count\"]).round(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Term          Course Description                   Session  \\\n",
      "0    Spring 2022   Advanced Game Development       Seven Week - Second   \n",
      "1    Spring 2022         Advanced Web Design  Regular Academic Session   \n",
      "2    Spring 2022        Algorithms for Games  Regular Academic Session   \n",
      "3    Spring 2022  Applied Data Visualization  Regular Academic Session   \n",
      "4    Spring 2022     Artificial Intelligence  Regular Academic Session   \n",
      "..           ...                         ...                       ...   \n",
      "413  Spring 2025      The Past and New Media        Seven Week - First   \n",
      "414  Spring 2025       Theories of New Media  Regular Academic Session   \n",
      "415  Spring 2025             Virtual Reality        Seven Week - First   \n",
      "416  Spring 2025     Visual Content Creation  Regular Academic Session   \n",
      "417  Spring 2025           eSport Industries        Seven Week - First   \n",
      "\n",
      "    Session Code                        Campus                  Facility  \\\n",
      "0            7W2  University of Arizona - Main                    Online   \n",
      "1              1  University of Arizona - Main                    Online   \n",
      "2              1  University of Arizona - Main  R P Harvill Bldg, Rm 402   \n",
      "3              1                Arizona Online                    Online   \n",
      "4              1  University of Arizona - Main         Education, Rm 310   \n",
      "..           ...                           ...                       ...   \n",
      "413          7W1                Arizona Online                    Online   \n",
      "414            1  University of Arizona - Main            Flex In-Person   \n",
      "415          7W1                Arizona Online                    Online   \n",
      "416            1  University of Arizona - Main       The Commons, Rm 105   \n",
      "417          7W1                Arizona Online                    Online   \n",
      "\n",
      "     Room Capacity Subject Code Catalog Number Class Section  ... Start Date  \\\n",
      "0                1         GAME            452           101  ... 2022-03-14   \n",
      "1                1         ISTA            330           101  ... 2022-01-12   \n",
      "2               40         ISTA            425           001  ... 2022-01-12   \n",
      "3                1         ISTA            320           201  ... 2022-01-12   \n",
      "4               40         ISTA            450           001  ... 2022-01-12   \n",
      "..             ...          ...            ...           ...  ...        ...   \n",
      "413              1         ESOC            213           202  ... 2025-01-15   \n",
      "414             99         ESOC            314           002  ... 2025-01-15   \n",
      "415              1         ISTA            424           201  ... 2025-01-15   \n",
      "416            217         ESOC            200           001  ... 2025-01-15   \n",
      "417              1         GAME            311           201  ... 2025-01-15   \n",
      "\n",
      "      End Date  Class Meeting Number  Meeting Days Meeting Time Start  \\\n",
      "0   2022-05-04                     1             -           00:00:00   \n",
      "1   2022-05-04                     1             -           00:00:00   \n",
      "2   2022-05-04                     1            TR           14:00:00   \n",
      "3   2022-05-04                     1             -           00:00:00   \n",
      "4   2022-05-04                     1            MW           14:00:00   \n",
      "..         ...                   ...           ...                ...   \n",
      "413 2025-03-07                     1             -           00:00:00   \n",
      "414 2025-05-07                     2             -           00:00:00   \n",
      "415 2025-03-07                     1             -           00:00:00   \n",
      "416 2025-05-07                     1            TR           12:30:00   \n",
      "417 2025-03-07                     1             -           00:00:00   \n",
      "\n",
      "    Meeting Time End Total Enroll  Enrollment Capacity Instructor Count  IAS  \n",
      "0           00:00:00           14                   28                1  1.0  \n",
      "1           00:00:00           21                   28                1  1.0  \n",
      "2           15:15:00           19                   27                1  1.0  \n",
      "3           00:00:00            1                    5                1  1.0  \n",
      "4           15:15:00           15                   20                1  1.0  \n",
      "..               ...          ...                  ...              ...  ...  \n",
      "413         00:00:00           10                   40                1  1.0  \n",
      "414         00:00:00           10                   30                2  0.5  \n",
      "415         00:00:00            0                    0                1  1.0  \n",
      "416         13:45:00          103                  200                1  1.0  \n",
      "417         00:00:00            3                   40                1  1.0  \n",
      "\n",
      "[418 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sort by Term with semester_order_func\n",
    "df_IAS_term = df_IAS_term[df_IAS_term[\"Term\"].notna()]\n",
    "df_IAS_term = df_IAS_term.set_index([\"Term\", \"Course Description\"])\n",
    "df_IAS_term = df_IAS_term.loc[sorted(df_IAS_term.index, key=lambda x: semester_order_func(x[0]))]\n",
    "df_IAS_term = df_IAS_term.reset_index()\n",
    "\n",
    "print(df_IAS_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAS by Course Descriptions & Term:\n",
      "            Term          Course Description  Instructor Count  IAS\n",
      "0    Spring 2022   Advanced Game Development                 1  1.0\n",
      "1    Spring 2022         Advanced Web Design                 1  1.0\n",
      "2    Spring 2022        Algorithms for Games                 1  1.0\n",
      "3    Spring 2022  Applied Data Visualization                 1  1.0\n",
      "4    Spring 2022     Artificial Intelligence                 1  1.0\n",
      "..           ...                         ...               ...  ...\n",
      "413  Spring 2025      The Past and New Media                 1  1.0\n",
      "414  Spring 2025       Theories of New Media                 2  0.5\n",
      "415  Spring 2025             Virtual Reality                 1  1.0\n",
      "416  Spring 2025     Visual Content Creation                 1  1.0\n",
      "417  Spring 2025           eSport Industries                 1  1.0\n",
      "\n",
      "[418 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Smaller DF for printing; sort semesters with my function\n",
    "df_IAS_term_small = df_IAS_term[[\"Term\", \"Course Description\", \"Instructor Count\", \"IAS\"]]\n",
    "\n",
    "print(\"IAS by Course Descriptions & Term:\")\n",
    "print(df_IAS_term_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IAS by Term - Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IAS Summary Stats for Fall 2022:\n",
      "Mean IAS: 0.95\n",
      "Median IAS: 1.0\n",
      "Standard Deviation: 0.16\n",
      "IAS Score Counts:\n",
      "  IAS 0.5: 6 courses\n",
      "  IAS 1.0: 49 courses\n",
      "\n",
      "IAS Summary Stats for Fall 2023:\n",
      "Mean IAS: 0.93\n",
      "Median IAS: 1.0\n",
      "Standard Deviation: 0.17\n",
      "IAS Score Counts:\n",
      "  IAS 0.5: 8 courses\n",
      "  IAS 1.0: 52 courses\n",
      "\n",
      "IAS Summary Stats for Fall 2024:\n",
      "Mean IAS: 0.91\n",
      "Median IAS: 1.0\n",
      "Standard Deviation: 0.2\n",
      "IAS Score Counts:\n",
      "  IAS 0.33: 1 courses\n",
      "  IAS 0.5: 9 courses\n",
      "  IAS 1.0: 50 courses\n",
      "\n",
      "IAS Summary Stats for Spring 2022:\n",
      "Mean IAS: 0.92\n",
      "Median IAS: 1.0\n",
      "Standard Deviation: 0.18\n",
      "IAS Score Counts:\n",
      "  IAS 0.5: 9 courses\n",
      "  IAS 1.0: 49 courses\n",
      "\n",
      "IAS Summary Stats for Spring 2023:\n",
      "Mean IAS: 0.95\n",
      "Median IAS: 1.0\n",
      "Standard Deviation: 0.15\n",
      "IAS Score Counts:\n",
      "  IAS 0.5: 6 courses\n",
      "  IAS 1.0: 56 courses\n",
      "\n",
      "IAS Summary Stats for Spring 2024:\n",
      "Mean IAS: 0.93\n",
      "Median IAS: 1.0\n",
      "Standard Deviation: 0.18\n",
      "IAS Score Counts:\n",
      "  IAS 0.33: 1 courses\n",
      "  IAS 0.5: 7 courses\n",
      "  IAS 1.0: 52 courses\n",
      "\n",
      "IAS Summary Stats for Spring 2025:\n",
      "Mean IAS: 0.92\n",
      "Median IAS: 1.0\n",
      "Standard Deviation: 0.18\n",
      "IAS Score Counts:\n",
      "  IAS 0.5: 10 courses\n",
      "  IAS 1.0: 53 courses\n"
     ]
    }
   ],
   "source": [
    "# For Loop for our summary stats (mean, median, std, min/max)  \n",
    "for df_semester, group in df_IAS_term_small.groupby(\"Term\"):\n",
    "\n",
    "    print(f\"\\nIAS Summary Stats for {df_semester}:\") \n",
    "\n",
    "    # Summary stats (mean, median, std)\n",
    "    ias_mean = round(group[\"IAS\"].mean(), 2)\n",
    "    ias_median = round(group[\"IAS\"].median(), 2)\n",
    "    ias_std = round(group[\"IAS\"].std(), 2)\n",
    "    print(f\"Mean IAS: {ias_mean}\")\n",
    "    print(f\"Median IAS: {ias_median}\")\n",
    "    print(f\"Standard Deviation: {ias_std}\")\n",
    "\n",
    "    # Counts by IAS score within this term\n",
    "    ias_counts = group[\"IAS\"].value_counts().sort_index()\n",
    "    print(\"IAS Score Counts:\")\n",
    "    for ias_score in sorted(ias_counts.index):\n",
    "        count = ias_counts[ias_score]\n",
    "        print(f\"  IAS {ias_score}: {count} courses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Composite Bottleneck Index (CBI) Data Frames</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make CBI Data Frame - Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Course Description    DR  OFS   IAS  PCS\n",
      "0       Advanced Game Development  0.30    1  0.50    1\n",
      "1             Advanced Web Design  0.33    3  0.50    1\n",
      "2            Algorithms for Games  0.68    2  1.00    1\n",
      "3   Applied Cyberinfrastruct Conc  0.14    3  1.00    1\n",
      "4      Applied Data Visualization  0.68    1  0.25    1\n",
      "..                            ...   ...  ...   ...  ...\n",
      "76          Theories of New Media  0.49    1  0.33    0\n",
      "77       User Interf+Website Dsgn  0.06    3  1.00    0\n",
      "78                Virtual Reality  0.48    1  0.50    1\n",
      "79        Visual Content Creation  0.52    3  1.00    0\n",
      "80              eSport Industries  0.70    1  1.00    0\n",
      "\n",
      "[81 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# CBI Total Data Frame - Merge on \"Course Description\"\n",
    "df_CBI = df_avg_DR.merge(df_OFS_small, on= \"Course Description\", how= \"outer\")\n",
    "df_CBI = df_CBI.merge(df_IAS_tot_small, on=\"Course Description\", how= \"outer\")\n",
    "df_CBI = df_CBI.merge(df_PCS_scores, on= \"Course Description\", how=\"outer\")\n",
    "\n",
    "df_CBI.drop(columns=[\"TermCount\", \"Instructor Count\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "print(\"CBI Data Frame by Totals:\")\n",
    "print(df_CBI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make CBI Data Frame - By Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Term         Course Description    DR  OFS  IAS  PCS\n",
      "0      Fall 2022  Advanced Game Development  0.29  1.0  1.0    1\n",
      "1      Fall 2023  Advanced Game Development   NaN  NaN  1.0    1\n",
      "2      Fall 2024  Advanced Game Development  0.18  1.0  1.0    1\n",
      "3    Spring 2022  Advanced Game Development  0.50  1.0  1.0    1\n",
      "4    Spring 2023  Advanced Game Development  0.32  1.0  1.0    1\n",
      "..           ...                        ...   ...  ...  ...  ...\n",
      "477    Fall 2024          eSport Industries  0.74  1.0  1.0    0\n",
      "478  Spring 2022          eSport Industries  0.97  1.0  1.0    0\n",
      "479  Spring 2023          eSport Industries  0.49  1.0  1.0    0\n",
      "480  Spring 2024          eSport Industries  0.50  1.0  1.0    0\n",
      "481  Spring 2025          eSport Industries  0.50  1.0  1.0    0\n",
      "\n",
      "[482 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# CBI By Term Data Frame - Merge on \"Course Description\" and/or [\"Term\", \"Course Description\"]\n",
    "df_CBI_term = df_term_avg_DR.merge(df_OFS_small, on= \"Course Description\", how= \"outer\")\n",
    "df_CBI_term = df_CBI_term.merge(df_IAS_term_small, on=[\"Term\", \"Course Description\"], how= \"outer\")\n",
    "df_CBI_term = df_CBI_term.merge(df_PCS_scores, on= \"Course Description\", how=\"outer\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_CBI_term.drop(columns=[\"TermCount\", \"Instructor Count\"], inplace=True, errors=\"ignore\")   # Drop exta columns\n",
    "\n",
    "# print(\"Testing CBI Data Frame by Term:\")\n",
    "# print(df_CBI_term) # 482 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Term             Course Description    DR  OFS  IAS  PCS\n",
      "0      Fall 2021            Advanced Web Design  0.26  3.0  NaN    1\n",
      "1      Fall 2021           Algorithms for Games  0.52  2.0  NaN    1\n",
      "2      Fall 2021  Applied Cyberinfrastruct Conc  0.22  3.0  NaN    1\n",
      "3      Fall 2021     Applied Data Visualization  0.72  1.0  NaN    1\n",
      "4      Fall 2021  Bayesian Modeling & Inference  0.09  3.0  NaN    1\n",
      "..           ...                            ...   ...  ...  ...  ...\n",
      "474  Spring 2025         The Past and New Media  0.34  1.0  1.0    0\n",
      "475  Spring 2025          Theories of New Media  0.32  1.0  0.5    0\n",
      "476  Spring 2025                Virtual Reality  0.46  1.0  1.0    1\n",
      "477  Spring 2025        Visual Content Creation  0.52  3.0  1.0    0\n",
      "478  Spring 2025              eSport Industries  0.50  1.0  1.0    0\n",
      "\n",
      "[479 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sort Terms with my semester_order_func function\n",
    "df_CBI_term = df_CBI_term[df_CBI_term[\"Term\"].notna()]              # Some of the Terms are loading in as Missing (dropped 2 rows)\n",
    "df_CBI_term = df_CBI_term.set_index([\"Term\", \"Course Description\"]) # Set index to group by\n",
    "df_CBI_term = df_CBI_term.loc[sorted(df_CBI_term.index, key=lambda x: semester_order_func(x[0]))] # Multi-Index sort function\n",
    "df_CBI_term = df_CBI_term.reset_index()\n",
    "\n",
    "print(\"CBI Data Frame by Term:\")\n",
    "print(df_CBI_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBI Total - Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_tot = {\"DR\": 1, \"OFS\": 1,\n",
    "               \"IAS\": 1, \"PCS\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBI by Term - Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_term = {\"DR\": 1, \"OFS\": 1,\n",
    "               \"IAS\": 1, \"PCS\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Composite Bottleneck Index (CBI) Analysis </h2>\n",
    "CBI = (DR * w1) + (OFS * w2) + (IAS * w3) + (PCS * w4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBI - Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBI Analysis by Totals, All Scores\n",
      "               Course Description    DR  OFS   IAS  PCS   CBI\n",
      "0       Advanced Game Development  0.30    1  0.50    1  2.80\n",
      "1             Advanced Web Design  0.33    3  0.50    1  4.83\n",
      "2            Algorithms for Games  0.68    2  1.00    1  4.68\n",
      "3   Applied Cyberinfrastruct Conc  0.14    3  1.00    1  5.14\n",
      "4      Applied Data Visualization  0.68    1  0.25    1  2.93\n",
      "..                            ...   ...  ...   ...  ...   ...\n",
      "76          Theories of New Media  0.49    1  0.33    0  1.82\n",
      "77       User Interf+Website Dsgn  0.06    3  1.00    0  4.06\n",
      "78                Virtual Reality  0.48    1  0.50    1  2.98\n",
      "79        Visual Content Creation  0.52    3  1.00    0  4.52\n",
      "80              eSport Industries  0.70    1  1.00    0  2.70\n",
      "\n",
      "[81 rows x 6 columns]\n",
      "\n",
      "CBI Analysis by Totals\n",
      "               Course Description   CBI\n",
      "0       Advanced Game Development  2.80\n",
      "1             Advanced Web Design  4.83\n",
      "2            Algorithms for Games  4.68\n",
      "3   Applied Cyberinfrastruct Conc  5.14\n",
      "4      Applied Data Visualization  2.93\n",
      "..                            ...   ...\n",
      "76          Theories of New Media  1.82\n",
      "77       User Interf+Website Dsgn  4.06\n",
      "78                Virtual Reality  2.98\n",
      "79        Visual Content Creation  4.52\n",
      "80              eSport Industries  2.70\n",
      "\n",
      "[81 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_CBI_analysis = df_CBI.copy()\n",
    "\n",
    "# Add CBI column\n",
    "# CBI = (DR * w1) + (OFS * w2) + (IAS * w3) + (PCS * w4)\n",
    "df_CBI_analysis[\"CBI\"] = ((df_CBI_analysis[\"DR\"]  * weights_tot[\"DR\"] +\n",
    "                          df_CBI_analysis[\"OFS\"] * weights_tot[\"OFS\"] +\n",
    "                          df_CBI_analysis[\"IAS\"] * weights_tot[\"IAS\"] +\n",
    "                          df_CBI_analysis[\"PCS\"] * weights_tot[\"PCS\"]).round(2))\n",
    "\n",
    "print(\"CBI Analysis by Totals, All Scores\")\n",
    "print(df_CBI_analysis)\n",
    "\n",
    "print(\"\\nCBI Analysis by Totals\")\n",
    "print(df_CBI_analysis[[\"Course Description\", \"CBI\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBI Total - Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBI Summary Stats (Overall):\n",
      "Mean CBI: 3.19\n",
      "Median CBI: 3.01\n",
      "Standard Deviation: 1.04\n",
      "Min CBI: 1.66 — Courses: ['Intellectual Property/Copyrigh']\n",
      "Max CBI: 5.63 — Courses: ['Foundation of Info & Inference']\n",
      "\n",
      "10 Highest CBI Courses:\n",
      "                Course Description   CBI\n",
      "32  Foundation of Info & Inference  5.63\n",
      "46        Intro to Creative Coding  5.43\n",
      "33                         Game AI  5.41\n",
      "3    Applied Cyberinfrastruct Conc  5.14\n",
      "65                      STEM Games  5.05\n",
      "7    Bayesian Modeling & Inference  5.03\n",
      "10    Computational Social Science  5.02\n",
      "1              Advanced Web Design  4.83\n",
      "2             Algorithms for Games  4.68\n",
      "55   Monetizing Independent Gaming  4.60\n",
      "\n",
      "10 Lowest CBI Courses:\n",
      "                Course Description   CBI\n",
      "44  Intellectual Property/Copyrigh  1.66\n",
      "23                Digital Dilemmas  1.74\n",
      "26  Digital Storytelling & Culture  1.82\n",
      "76           Theories of New Media  1.82\n",
      "62   Publishing:Papyrus to E-Books  1.91\n",
      "63   Qualitative Internet Research  1.95\n",
      "31       Ethics in a Digital World  2.00\n",
      "69      Social Media and Ourselves  2.00\n",
      "24  Digital Discourse and Identity  2.05\n",
      "64            Quantitative Methods  2.08\n"
     ]
    }
   ],
   "source": [
    "# Overall stats cbi_tot\n",
    "cbi_tot_mean = round(df_CBI_analysis[\"CBI\"].mean(), 2)\n",
    "cbi_tot_median = round(df_CBI_analysis[\"CBI\"].median(), 2)\n",
    "cbi_tot_std = round(df_CBI_analysis[\"CBI\"].std(), 2)\n",
    "\n",
    "print(\"CBI Summary Stats (Overall):\")\n",
    "print(f\"Mean CBI: {cbi_tot_mean}\")\n",
    "print(f\"Median CBI: {cbi_tot_median}\")\n",
    "print(f\"Standard Deviation: {cbi_tot_std}\")\n",
    "\n",
    "\n",
    "# DR min/max and course name\n",
    "cbi_tot_min = round(df_CBI_analysis[\"CBI\"].min(), 2)\n",
    "cbi_tot_max = round(df_CBI_analysis[\"CBI\"].max(), 2)\n",
    "cbi_tot_course_min = df_CBI_analysis.loc[df_CBI_analysis[\"CBI\"] == cbi_tot_min, \"Course Description\"].tolist() #Course name(s) as list\n",
    "cbi_tot_course_max = df_CBI_analysis.loc[df_CBI_analysis[\"CBI\"] == cbi_tot_max, \"Course Description\"].tolist()\n",
    "\n",
    "print(f\"Min CBI: {cbi_tot_min} — Courses: {cbi_tot_course_min}\")\n",
    "print(f\"Max CBI: {cbi_tot_max} — Courses: {cbi_tot_course_max}\")\n",
    "\n",
    "# Top highest and lowest DR courses\n",
    "high_low_count = 10\n",
    "top_cbi_tot = df_CBI_analysis.nlargest(high_low_count, \"CBI\")\n",
    "bottom_cbi_tot = df_CBI_analysis.nsmallest(high_low_count, \"CBI\")\n",
    "\n",
    "print(f\"\\n{high_low_count} Highest CBI Courses:\")\n",
    "#print(top_cbi_tot)\n",
    "print(top_cbi_tot[[\"Course Description\", \"CBI\"]])\n",
    "print(f\"\\n{high_low_count} Lowest CBI Courses:\")\n",
    "#print(bottom_cbi_tot)\n",
    "print(bottom_cbi_tot[[\"Course Description\", \"CBI\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBI Analysis by Term, All Scores\n",
      "            Term             Course Description    DR  OFS  IAS  PCS   CBI\n",
      "0      Fall 2021            Advanced Web Design  0.26  3.0  NaN    1   NaN\n",
      "1      Fall 2021           Algorithms for Games  0.52  2.0  NaN    1   NaN\n",
      "2      Fall 2021  Applied Cyberinfrastruct Conc  0.22  3.0  NaN    1   NaN\n",
      "3      Fall 2021     Applied Data Visualization  0.72  1.0  NaN    1   NaN\n",
      "4      Fall 2021  Bayesian Modeling & Inference  0.09  3.0  NaN    1   NaN\n",
      "..           ...                            ...   ...  ...  ...  ...   ...\n",
      "474  Spring 2025         The Past and New Media  0.34  1.0  1.0    0  2.34\n",
      "475  Spring 2025          Theories of New Media  0.32  1.0  0.5    0  1.82\n",
      "476  Spring 2025                Virtual Reality  0.46  1.0  1.0    1  3.46\n",
      "477  Spring 2025        Visual Content Creation  0.52  3.0  1.0    0  4.52\n",
      "478  Spring 2025              eSport Industries  0.50  1.0  1.0    0  2.50\n",
      "\n",
      "[479 rows x 7 columns]\n",
      "\n",
      "CBI Analysis by Term\n",
      "            Term             Course Description   CBI\n",
      "0      Fall 2021            Advanced Web Design   NaN\n",
      "1      Fall 2021           Algorithms for Games   NaN\n",
      "2      Fall 2021  Applied Cyberinfrastruct Conc   NaN\n",
      "3      Fall 2021     Applied Data Visualization   NaN\n",
      "4      Fall 2021  Bayesian Modeling & Inference   NaN\n",
      "..           ...                            ...   ...\n",
      "474  Spring 2025         The Past and New Media  2.34\n",
      "475  Spring 2025          Theories of New Media  1.82\n",
      "476  Spring 2025                Virtual Reality  3.46\n",
      "477  Spring 2025        Visual Content Creation  4.52\n",
      "478  Spring 2025              eSport Industries  2.50\n",
      "\n",
      "[479 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_CBI_term_analysis = df_CBI_term.copy()\n",
    "\n",
    "df_CBI_term_analysis[\"CBI\"] = (df_CBI_term_analysis[\"DR\"]  * weights_tot[\"DR\"] +\n",
    "                               df_CBI_term_analysis[\"OFS\"] * weights_tot[\"OFS\"] +\n",
    "                               df_CBI_term_analysis[\"IAS\"] * weights_tot[\"IAS\"] +\n",
    "                               df_CBI_term_analysis[\"PCS\"] * weights_tot[\"PCS\"])\n",
    "\n",
    "print(\"CBI Analysis by Term, All Scores\")\n",
    "print(df_CBI_term_analysis)\n",
    "\n",
    "print(\"\\nCBI Analysis by Term\")\n",
    "print(df_CBI_term_analysis[[\"Term\", \"Course Description\", \"CBI\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBI by Term - Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🗓 CBI Summary for Fall 2021\n",
      "Mean CBI: nan\n",
      "Median CBI: nan\n",
      "Standard Deviation: nan\n",
      "Min CBI: 0.0 on Courses: []\n",
      "Max CBI: 0.98 on Courses: []\n",
      "\n",
      "Fall 2021: 10 Highest CBI Courses:\n",
      "            Course Description  CBI\n",
      "           Advanced Web Design  NaN\n",
      "          Algorithms for Games  NaN\n",
      " Applied Cyberinfrastruct Conc  NaN\n",
      "    Applied Data Visualization  NaN\n",
      " Bayesian Modeling & Inference  NaN\n",
      "  Collaborating: Online Commun  NaN\n",
      "Computational Thinking & Doing  NaN\n",
      "        Computing and the Arts  NaN\n",
      "              Data Engineering  NaN\n",
      "     Data Mining and Discovery  NaN\n",
      "\n",
      " Fall 2021: 10 Lowest CBI Courses:\n",
      "            Course Description  CBI\n",
      "           Advanced Web Design  NaN\n",
      "          Algorithms for Games  NaN\n",
      " Applied Cyberinfrastruct Conc  NaN\n",
      "    Applied Data Visualization  NaN\n",
      " Bayesian Modeling & Inference  NaN\n",
      "  Collaborating: Online Commun  NaN\n",
      "Computational Thinking & Doing  NaN\n",
      "        Computing and the Arts  NaN\n",
      "              Data Engineering  NaN\n",
      "     Data Mining and Discovery  NaN\n",
      "\n",
      "🗓 CBI Summary for Fall 2022\n",
      "Mean CBI: 3.09\n",
      "Median CBI: 2.95\n",
      "Standard Deviation: 0.81\n",
      "Min CBI: 0.0 on Courses: ['Quantitative Methods']\n",
      "Max CBI: 0.98 on Courses: ['Intro to Creative Coding']\n",
      "\n",
      "Fall 2022: 10 Highest CBI Courses:\n",
      "            Course Description  CBI\n",
      "      Intro to Creative Coding 5.92\n",
      "           Installation Design 4.96\n",
      "               Neural Networks 4.88\n",
      "          Algorithms for Games 4.70\n",
      "    Instructional Technologies 4.52\n",
      "    Applied Data Visualization 3.94\n",
      "Computational Thinking & Doing 3.89\n",
      "             Dealing with Data 3.79\n",
      "   Great Ideas of the Info Age 3.74\n",
      "Statistic Foundations Info Age 3.71\n",
      "\n",
      " Fall 2022: 10 Lowest CBI Courses:\n",
      "            Course Description  CBI\n",
      "          Quantitative Methods 2.04\n",
      "            Intro to Info Tech 2.10\n",
      "Intellectual Property/Copyrigh 2.13\n",
      "       Social Media Strategies 2.15\n",
      "Digital Storytelling & Culture 2.20\n",
      "          Information Security 2.22\n",
      "   Introduction to Game Design 2.24\n",
      "         Database Dev and Mgmt 2.31\n",
      "  Intro Web Design-Development 2.35\n",
      "              Online Searching 2.35\n",
      "\n",
      "🗓 CBI Summary for Fall 2023\n",
      "Mean CBI: 3.05\n",
      "Median CBI: 2.97\n",
      "Standard Deviation: 0.74\n",
      "Min CBI: 0.0 on Courses: ['Ethics in a Digital World', 'Intro to Info Tech']\n",
      "Max CBI: 0.98 on Courses: ['Algorithms for Games']\n",
      "\n",
      "Fall 2023: 10 Highest CBI Courses:\n",
      "            Course Description  CBI\n",
      "          Algorithms for Games 4.67\n",
      "       Artificial Intelligence 4.56\n",
      "               Neural Networks 4.54\n",
      "               Esports Casting 4.47\n",
      "                   Applied NLP 4.14\n",
      "Computational Thinking & Doing 3.96\n",
      "Statistic Foundations Info Age 3.95\n",
      "   Great Ideas of the Info Age 3.94\n",
      "    Intro. to Game Development 3.94\n",
      "    Applied Data Visualization 3.93\n",
      "\n",
      " Fall 2023: 10 Lowest CBI Courses:\n",
      "            Course Description  CBI\n",
      "     Ethics in a Digital World 2.05\n",
      "            Intro to Info Tech 2.05\n",
      "           Technology of Sound 2.10\n",
      "   Learning in Information Age 2.15\n",
      " Publishing:Papyrus to E-Books 2.17\n",
      "Digital Storytelling & Culture 2.18\n",
      "Intellectual Property/Copyrigh 2.19\n",
      "       Social Media Strategies 2.19\n",
      "    Social Media and Ourselves 2.25\n",
      "          Information Security 2.26\n",
      "\n",
      "🗓 CBI Summary for Fall 2024\n",
      "Mean CBI: 3.08\n",
      "Median CBI: 3.0\n",
      "Standard Deviation: 0.81\n",
      "Min CBI: 0.0 on Courses: ['Technology of Sound']\n",
      "Max CBI: 0.98 on Courses: ['Neural Networks']\n",
      "\n",
      "Fall 2024: 10 Highest CBI Courses:\n",
      "           Course Description  CBI\n",
      "              Neural Networks 5.14\n",
      "Bayesian Modeling & Inference 5.00\n",
      "         Algorithms for Games 4.89\n",
      "          Installation Design 4.80\n",
      "           Princ Data Science 4.67\n",
      "  Info Trust and Manipulation 4.27\n",
      "      Artificial Intelligence 4.12\n",
      "                  Applied NLP 4.10\n",
      "   Intro. to Game Development 3.98\n",
      "  Great Ideas of the Info Age 3.82\n",
      "\n",
      " Fall 2024: 10 Lowest CBI Courses:\n",
      "            Course Description  CBI\n",
      "           Technology of Sound 1.96\n",
      "     Ethics in a Digital World 2.01\n",
      "       Social Media Strategies 2.03\n",
      "            Intro to Info Tech 2.08\n",
      "        Computing and the Arts 2.10\n",
      "Digital Storytelling & Culture 2.10\n",
      "   Learning in Information Age 2.15\n",
      "         Database Dev and Mgmt 2.20\n",
      "              Online Searching 2.21\n",
      "Intellectual Property/Copyrigh 2.23\n",
      "\n",
      "🗓 CBI Summary for Spring 2022\n",
      "Mean CBI: 3.18\n",
      "Median CBI: 2.97\n",
      "Standard Deviation: 0.88\n",
      "Min CBI: 0.0 on Courses: ['Digital Dilemmas']\n",
      "Max CBI: 0.98 on Courses: ['Foundation of Info & Inference']\n",
      "\n",
      "Spring 2022: 10 Highest CBI Courses:\n",
      "            Course Description  CBI\n",
      "Foundation of Info & Inference 5.48\n",
      "           Advanced Web Design 5.39\n",
      "       Artificial Intelligence 4.75\n",
      "          Algorithms for Games 4.70\n",
      "     Intro to Digital Cultures 4.67\n",
      "    Instructional Technologies 4.48\n",
      "            Princ Data Science 4.48\n",
      "     Designing an Installation 4.12\n",
      "      User Interf+Website Dsgn 4.03\n",
      "    Applied Data Visualization 3.94\n",
      "\n",
      " Spring 2022: 10 Lowest CBI Courses:\n",
      "            Course Description  CBI\n",
      "              Digital Dilemmas 1.99\n",
      " Publishing:Papyrus to E-Books 2.03\n",
      "Intellectual Property/Copyrigh 2.07\n",
      "            Intro to Info Tech 2.07\n",
      " Info MM Design & Moving Image 2.08\n",
      "         Theories of New Media 2.10\n",
      "          Quantitative Methods 2.14\n",
      "         Database Dev and Mgmt 2.20\n",
      "    Social Media and Ourselves 2.25\n",
      "       Social Media Strategies 2.27\n",
      "\n",
      "🗓 CBI Summary for Spring 2023\n",
      "Mean CBI: 3.16\n",
      "Median CBI: 3.0\n",
      "Standard Deviation: 0.75\n",
      "Min CBI: 0.0 on Courses: ['Digital Dilemmas']\n",
      "Max CBI: 0.98 on Courses: []\n",
      "\n",
      "Spring 2023: 10 Highest CBI Courses:\n",
      "            Course Description  CBI\n",
      "  Computational Social Science 5.03\n",
      "           Installation Design 4.88\n",
      "               Esports Casting 4.69\n",
      "          Algorithms for Games 4.63\n",
      "     Intro to Digital Cultures 4.40\n",
      "                Special Topics 4.35\n",
      "       Artificial Intelligence 4.23\n",
      "                   Applied NLP 4.12\n",
      "Computational Thinking & Doing 3.82\n",
      "    Applied Data Visualization 3.77\n",
      "\n",
      " Spring 2023: 10 Lowest CBI Courses:\n",
      "           Course Description  CBI\n",
      "             Digital Dilemmas 1.95\n",
      "           Intro to Info Tech 2.11\n",
      "      Social Media Strategies 2.14\n",
      "        Database Dev and Mgmt 2.18\n",
      "   Social Media and Ourselves 2.21\n",
      "      Disruptive Technologies 2.26\n",
      "             Online Searching 2.36\n",
      "      Gamification in Society 2.46\n",
      "Publishing:Papyrus to E-Books 2.46\n",
      "Qualitative Internet Research 2.46\n",
      "\n",
      "🗓 CBI Summary for Spring 2024\n",
      "Mean CBI: 3.1\n",
      "Median CBI: 2.95\n",
      "Standard Deviation: 0.86\n",
      "Min CBI: 0.0 on Courses: ['Theories of New Media']\n",
      "Max CBI: 0.98 on Courses: ['Game AI']\n",
      "\n",
      "Spring 2024: 10 Highest CBI Courses:\n",
      "            Course Description  CBI\n",
      "                       Game AI 5.41\n",
      "                    STEM Games 5.07\n",
      "  Computational Social Science 5.00\n",
      " Monetizing Independent Gaming 4.62\n",
      "     Intro to Digital Cultures 4.48\n",
      "               Esports Casting 4.44\n",
      "       Artificial Intelligence 4.15\n",
      "                   Applied NLP 4.12\n",
      "    Applied Data Visualization 3.97\n",
      "Computational Thinking & Doing 3.93\n",
      "\n",
      " Spring 2024: 10 Lowest CBI Courses:\n",
      "            Course Description  CBI\n",
      "         Theories of New Media 1.85\n",
      "Digital Storytelling & Culture 1.99\n",
      "       Social Media Strategies 2.03\n",
      "            Intro to Info Tech 2.11\n",
      "Intellectual Property/Copyrigh 2.13\n",
      "     Ethics in a Digital World 2.15\n",
      "   Learning in Information Age 2.15\n",
      "    Social Media and Ourselves 2.17\n",
      "         Database Dev and Mgmt 2.18\n",
      "        The Past and New Media 2.30\n",
      "\n",
      "🗓 CBI Summary for Spring 2025\n",
      "Mean CBI: 3.17\n",
      "Median CBI: 2.98\n",
      "Standard Deviation: 0.94\n",
      "Min CBI: 0.0 on Courses: ['Theories of New Media']\n",
      "Max CBI: 0.98 on Courses: ['Game AI']\n",
      "\n",
      "Spring 2025: 10 Highest CBI Courses:\n",
      "           Course Description  CBI\n",
      "                      Game AI 5.41\n",
      "          Advanced Web Design 5.40\n",
      "Applied Cyberinfrastruct Conc 5.05\n",
      "                   STEM Games 5.03\n",
      "Bayesian Modeling & Inference 5.00\n",
      "          Installation Design 4.83\n",
      "Monetizing Independent Gaming 4.57\n",
      "      Visual Content Creation 4.52\n",
      "      Artificial Intelligence 4.38\n",
      "           Princ Data Science 4.16\n",
      "\n",
      " Spring 2025: 10 Lowest CBI Courses:\n",
      "            Course Description  CBI\n",
      "         Theories of New Media 1.82\n",
      "  Intro Web Design-Development 1.90\n",
      "       Social Media Strategies 1.96\n",
      "Digital Storytelling & Culture 1.98\n",
      "         Database Dev and Mgmt 2.14\n",
      "            Intro to Info Tech 2.14\n",
      "   Learning in Information Age 2.15\n",
      "Intellectual Property/Copyrigh 2.23\n",
      "        Computing and the Arts 2.28\n",
      "              Online Searching 2.30\n"
     ]
    }
   ],
   "source": [
    "# For Loop for our summary stats (mean, median, std, min/max) and top/bottom courses\n",
    "for df_semester, group in df_CBI_term_analysis.groupby(\"Term\"):\n",
    "    # Summary stats (mean, median, std)\n",
    "    cbi_term_mean = round(group[\"CBI\"].mean(), 2)\n",
    "    cbi_term_median = round(group[\"CBI\"].median(), 2)\n",
    "    cbi_term_std = round(group[\"CBI\"].std(), 2)\n",
    "    print(f\"\\n🗓 CBI Summary for {df_semester}\") # emoji to make it easier to read\n",
    "    print(f\"Mean CBI: {cbi_term_mean}\")\n",
    "    print(f\"Median CBI: {cbi_term_median}\")\n",
    "    print(f\"Standard Deviation: {cbi_term_std}\")\n",
    "\n",
    "    # Min/Max with course name(s)\n",
    "    cbi_term_min = round(group[\"CBI\"].min(), 2)\n",
    "    cbi_term_max = round(group[\"CBI\"].max(), 2)\n",
    "    cbi_term_course_min = group.loc[group[\"CBI\"] == cbi_term_min, \"Course Description\"].tolist()\n",
    "    cbi_term_course_max = group.loc[group[\"CBI\"] == cbi_term_max, \"Course Description\"].tolist()\n",
    "    print(f\"Min CBI: {dr_min} on Courses: {cbi_term_course_min}\")\n",
    "    print(f\"Max CBI: {dr_max} on Courses: {cbi_term_course_max}\")\n",
    "\n",
    "    #Top/Bottom \n",
    "    high_low_count = 10\n",
    "    top_cbi_term = group.nlargest(high_low_count, \"CBI\")[[\"Course Description\", \"CBI\"]]\n",
    "    bottom_cbi_term = group.nsmallest(high_low_count, \"CBI\")[[\"Course Description\", \"CBI\"]]\n",
    "    print(f\"\\n{df_semester}: {high_low_count} Highest CBI Courses:\")\n",
    "    print(top_cbi_term.to_string(index=False))\n",
    "    print(f\"\\n {df_semester}: {high_low_count} Lowest CBI Courses:\")\n",
    "    print(bottom_cbi_term.to_string(index=False))\n",
    "\n",
    "# note Fall 2021 isn't calculating because of missing data ??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
